#!/usr/bin/env python3
"""
EXP3 ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
python exp3_analysis.py --results_dir _/data/output --config exp3_training.json

ë””ë ‰í† ë¦¬ êµ¬ì¡°:
data/output/
â””â”€â”€ exp3_cell_optimization_training_fixed/
    â””â”€â”€ 2025_07_17/
        â””â”€â”€ 120233/
            â”œâ”€â”€ ecotf_s0_p43_0/  # ì‹œë“œë³„ í´ë”
            â”‚   â”œâ”€â”€ exp3_learning_progress_fixed.json
            â”‚   â””â”€â”€ exp3_trained_model_fixed.json
            â”œâ”€â”€ ecotf_s1_p43_0/
            â””â”€â”€ analysis_results/  # ë¶„ì„ ê²°ê³¼
"""

import json
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import argparse
import pandas as pd
from datetime import datetime
from scipy import stats
import os
import sys
from collections import defaultdict
import re
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker

# í•œê¸€ í°íŠ¸ ì„¤ì •
import platform
import matplotlib as mpl
if platform.system() == 'Linux':
    plt.rcParams['font.family'] = 'DejaVu Sans'
    plt.rcParams['axes.unicode_minus'] = False

# ì „ì—­ ì„¤ì •
SEED_DISPLAY_COUNT = 10  # ëª¨ë“  ê·¸ë˜í”„ì—ì„œ í‘œì‹œí•  ì‹œë“œ ìˆ˜ í†µì¼
MOVING_AVG_WINDOW = 50  # ì´ë™í‰ê·  ì°½ í¬ê¸°


class EXP3MultiSeedAnalyzer:
    def __init__(self, results_dir, config_file=None, output_dir=None):
        self.results_dir = Path(results_dir)
        self.config_file = config_file
        self.output_dir = Path(output_dir) if output_dir else self.results_dir / 'analysis_results'
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
        self.all_results = defaultdict(list)
        self.metrics = {}
        self.seed_data = {}  # ì‹œë“œë³„ ë°ì´í„° ì €ì¥
        
    def find_seed_directories(self):
        """ìƒˆë¡œìš´ ë””ë ‰í† ë¦¬ êµ¬ì¡°ì—ì„œ ì‹œë“œë³„ í´ë” ì°¾ê¸°"""
        seed_dirs = []
        
        print(f"ğŸ” ê²°ê³¼ ë””ë ‰í† ë¦¬ íƒìƒ‰: {self.results_dir}")
        
        if not self.results_dir.exists():
            print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.results_dir}")
            return seed_dirs
        
        # ì‹œë“œ í´ë” íŒ¨í„´ (ì˜ˆ: ecotf_s0_p43_0, ecotf_s1_p43_0)
        seed_pattern = re.compile(r'.*_s(\d+)_p.*')
        
        # ì§ì ‘ í•˜ìœ„ ë””ë ‰í† ë¦¬ë“¤ í™•ì¸
        for item in self.results_dir.iterdir():
            if item.is_dir() and seed_pattern.match(item.name):
                # analysis_results í´ë”ëŠ” ì œì™¸
                if item.name != 'analysis_results':
                    seed_dirs.append(item)
        
        # ì‹œë“œ ë²ˆí˜¸ë¡œ ì •ë ¬
        seed_dirs.sort(key=lambda x: int(seed_pattern.match(x.name).group(1)))
        
        print(f"âœ… ë°œê²¬ëœ ì‹œë“œ í´ë”: {len(seed_dirs)}ê°œ")
        for seed_dir in seed_dirs[:5]:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
            print(f"   - {seed_dir.name}")
        if len(seed_dirs) > 5:
            print(f"   ... ê·¸ë¦¬ê³  {len(seed_dirs) - 5}ê°œ ë”")
        
        return seed_dirs
    
    def load_csv_data(self, csv_file):
        """CSV íŒŒì¼ì—ì„œ ì—í”¼ì†Œë“œ ë°ì´í„° ë¡œë“œ"""
        try:
            df = pd.read_csv(csv_file)
            
            # ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜ (ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜ì„± ìœ ì§€)
            episode_data = {
                'reward_history': df['reward'].tolist(),
                'selected_arm_history': df['selected_arm'].tolist(),
                'efficiency_history': df['efficiency'].tolist(),
                'throughput_history': df['throughput_mbps'].tolist(),
                'power_history': df['power_kw'].tolist(),
                'energy_saving_history': df['energy_saving_pct'].tolist(),
                'cumulative_regret_history': df['cumulative_regret'].tolist(),
                'timestamps': df['timestamp'].tolist(),
                'episodes': df['episode'].tolist()
            }
            
            # í†µê³„ ê³„ì‚°
            episode_data['statistics'] = {
                'reward_mean': df['reward'].mean(),
                'reward_std': df['reward'].std(),
                'efficiency_mean': df['efficiency'].mean(),
                'efficiency_std': df['efficiency'].std(),
                'throughput_mean': df['throughput_mbps'].mean(),
                'throughput_std': df['throughput_mbps'].std(),
                'energy_saving_mean': df['energy_saving_pct'].mean(),
                'energy_saving_std': df['energy_saving_pct'].std(),
                'final_cumulative_regret': df['cumulative_regret'].iloc[-1] if len(df) > 0 else 0
            }
            
            return episode_data
            
        except Exception as e:
            print(f"âŒ CSV íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None
        
    def load_seed_results(self, seed_dir):
        """ì‹œë“œ ë””ë ‰í† ë¦¬ì—ì„œ ê²°ê³¼ íŒŒì¼ ë¡œë“œ (JSON + CSV)"""
        progress_file = None
        model_file = None
        csv_file = None
        
        # í•´ë‹¹ ì‹œë“œ í´ë”ì—ì„œ íŒŒì¼ ì°¾ê¸°
        for file in seed_dir.iterdir():
            if 'learning_progress' in file.name and file.suffix == '.json':
                progress_file = file
            elif 'trained_model' in file.name and file.suffix == '.json':
                model_file = file
            elif 'episodes.csv' in file.name:
                csv_file = file
        
        if not progress_file:
            print(f"âš ï¸ {seed_dir.name}ì—ì„œ progress JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, None
        
        # JSON íŒŒì¼ ë¡œë“œ
        try:
            with open(progress_file, 'r') as f:
                progress_data = json.load(f)
            
            # model íŒŒì¼ì´ ì—†ìœ¼ë©´ progressì—ì„œ ì¶”ì¶œ
            if model_file and model_file.exists():
                with open(model_file, 'r') as f:
                    model_data = json.load(f)
            else:
                # progress_dataì—ì„œ model ì •ë³´ ì¶”ì¶œ
                model_data = {
                    'weights': progress_data.get('model_state', {}).get('weights', []),
                    'arms': self.extract_arms_from_progress(progress_data),
                    'total_episodes': progress_data.get('episode', 0)
                }
            
            # CSV íŒŒì¼ ë¡œë“œ ë° ë³‘í•©
            if csv_file and csv_file.exists():
                episode_data = self.load_csv_data(csv_file)
                if episode_data:
                    # progress_dataì— CSV ë°ì´í„° ë³‘í•©
                    progress_data.update(episode_data)
                    print(f"âœ… {seed_dir.name}: CSV ë°ì´í„° ë³‘í•© ì™„ë£Œ")
            else:
                # CSV íŒŒì¼ì´ ì—†ìœ¼ë©´ episode_data_csv ê²½ë¡œì—ì„œ ì°¾ê¸°
                csv_path = progress_data.get('episode_data_csv')
                if csv_path and Path(csv_path).exists():
                    episode_data = self.load_csv_data(csv_path)
                    if episode_data:
                        progress_data.update(episode_data)
                        print(f"âœ… {seed_dir.name}: CSV ë°ì´í„° ë³‘í•© ì™„ë£Œ (ê²½ë¡œ: {csv_path})")
                else:
                    print(f"âš ï¸ {seed_dir.name}: CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            return progress_data, model_data
            
        except Exception as e:
            print(f"âŒ {seed_dir.name} íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None, None
        
        
    def load_all_seeds(self):
        """ëª¨ë“  ì‹œë“œì˜ ë°ì´í„° ë¡œë“œ"""
        seed_dirs = self.find_seed_directories()
        
        if not seed_dirs:
            print("âŒ ë¶„ì„í•  ì‹œë“œ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        successful_loads = 0
        
        for seed_dir in seed_dirs:
            progress_data, model_data = self.load_seed_results(seed_dir)
            
            if progress_data and model_data:
                # ì‹œë“œ ë²ˆí˜¸ ì¶”ì¶œ
                seed_match = re.search(r'_s(\d+)_', seed_dir.name)
                seed_num = int(seed_match.group(1)) if seed_match else len(self.seed_data)
                
                self.seed_data[seed_num] = {
                    'progress': progress_data,
                    'model': model_data,
                    'dir': seed_dir
                }
                successful_loads += 1
        
        print(f"\nâœ… {successful_loads}/{len(seed_dirs)}ê°œ ì‹œë“œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        return successful_loads > 0
    
    def extract_arms_from_progress(self, progress_data):
        """progress_dataì—ì„œ arms ì •ë³´ ì¶”ì¶œ"""
        # best_arm ì •ë³´ì—ì„œ ì¶”ì¶œ ì‹œë„
        best_arm_info = progress_data.get('best_arm', {})
        if 'cells_to_turn_off' in best_arm_info:
            # ì „ì²´ arms ë¦¬ìŠ¤íŠ¸ë¥¼ ì¬êµ¬ì„±í•˜ê¸° ì–´ë ¤ìš°ë¯€ë¡œ None ë°˜í™˜
            return None
        return None    
    
    
    def calculate_seed_regret(self, progress_data, model_data):
        """ìˆ˜ì •ëœ í›„íšŒ(regret) ê³„ì‚° - CSV ë°ì´í„° í™œìš©"""
        
        # CSVì—ì„œ ë¡œë“œëœ ë°ì´í„° ì‚¬ìš©
        cumulative_regret_history = progress_data.get('cumulative_regret_history', [])
        reward_history = progress_data.get('reward_history', [])
        selected_arm_history = progress_data.get('selected_arm_history', [])
        
        if cumulative_regret_history:
            # ì´ë¯¸ ê³„ì‚°ëœ ëˆ„ì  regret ì‚¬ìš©
            # ìˆœê°„ regret ê³„ì‚°
            instant_regret = [0] + [cumulative_regret_history[i] - cumulative_regret_history[i-1] 
                                   for i in range(1, len(cumulative_regret_history))]
            
            # ìµœì  arm ì •ë³´ëŠ” JSONì˜ regret_statisticsì—ì„œ
            regret_stats = progress_data.get('performance_summary', {}).get('regret_statistics', {})
            best_arm_idx = regret_stats.get('best_arm_idx', -1)
            best_reward = regret_stats.get('best_arm_avg_reward', 0)
            
            return cumulative_regret_history, instant_regret, best_arm_idx, best_reward
        
        # cumulative_regretì´ ì—†ìœ¼ë©´ reward_historyì—ì„œ ê³„ì‚°
        if not reward_history or not selected_arm_history:
            return [], [], None, 0
        
        # ê° armì˜ í‰ê·  ë³´ìƒ ê³„ì‚°
        arm_rewards = defaultdict(list)
        for arm, reward in zip(selected_arm_history, reward_history):
            arm_rewards[arm].append(reward)
        
        # ìµœì  arm ì°¾ê¸°
        arm_avg_rewards = {}
        for arm, rewards in arm_rewards.items():
            arm_avg_rewards[arm] = np.mean(rewards)
        
        if not arm_avg_rewards:
            return [], [], None, 0
            
        best_arm = max(arm_avg_rewards, key=arm_avg_rewards.get)
        best_reward = arm_avg_rewards[best_arm]
        
        # ëˆ„ì  í›„íšŒ ê³„ì‚°
        instant_regret = []
        for t, (chosen_arm, reward) in enumerate(zip(selected_arm_history, reward_history)):
            regret = best_reward - reward
            instant_regret.append(max(0, regret))
        
        cumulative_regret = np.cumsum(instant_regret).tolist()
        
        return cumulative_regret, instant_regret, best_arm, best_reward
    
    
    def calculate_energy_savings(self, progress_data):
        """ì—ë„ˆì§€ ì ˆê°ìœ¨ ê³„ì‚° - CSV ë°ì´í„° í™œìš©"""
        
        # CSVì—ì„œ ì§ì ‘ ë¡œë“œëœ ì—ë„ˆì§€ ì ˆê° ë°ì´í„° ì‚¬ìš©
        energy_saving_history = progress_data.get('energy_saving_history', [])
        
        if energy_saving_history:
            return {
                'mean': np.mean(energy_saving_history),
                'std': np.std(energy_saving_history),
                'final': energy_saving_history[-1] if energy_saving_history else 0
            }
        
        # ëŒ€ì²´ ë°©ë²•: JSONì˜ performance_summary ì‚¬ìš©
        energy_stats = progress_data.get('performance_summary', {}).get('energy_statistics', {})
        if energy_stats:
            return {
                'mean': energy_stats.get('avg_energy_saving_all_on', 0),
                'std': energy_stats.get('std_energy_saving', 0),
                'final': energy_stats.get('current_energy_saving', 0)
            }
        
        return {'mean': 0, 'std': 0, 'final': 0}
    
    def analyze_performance(self):
        """ì„±ëŠ¥ ë¶„ì„ - CSVì™€ JSON ë°ì´í„° í†µí•©"""
        print("\nğŸ“Š ì„±ëŠ¥ ì§€í‘œ ë¶„ì„ ì¤‘...")
        
        for seed_num, data in self.seed_data.items():
            progress = data['progress']
            model = data['model']
            
            # ì—ë„ˆì§€ ì ˆê°ìœ¨ (CSV ë°ì´í„° í™œìš©)
            energy_savings = self.calculate_energy_savings(progress)
            self.all_results['energy_savings'].append(energy_savings['mean'])
            
            # í‰ê·  ë³´ìƒ (CSV ë°ì´í„°)
            reward_history = progress.get('reward_history', [])
            if reward_history:
                avg_reward = np.mean(reward_history[-100:])  # ë§ˆì§€ë§‰ 100ê°œ
            else:
                avg_reward = progress.get('performance_summary', {}).get('recent_avg_reward', 0)
            self.all_results['avg_rewards'].append(avg_reward)
            
            # Throughput (CSV ë°ì´í„°)
            throughput_history = progress.get('throughput_history', [])
            if throughput_history:
                avg_throughput = np.mean(throughput_history[-100:])
            else:
                throughput_stats = progress.get('performance_summary', {}).get('throughput_statistics', {})
                avg_throughput = throughput_stats.get('avg_throughput_mbps', 0)
            self.all_results['avg_throughputs'].append(avg_throughput)
            
            # ìµœì¢… ê°€ì¤‘ì¹˜ (JSON ë°ì´í„°)
            weights = model.get('weights', [])
            if not weights:
                weights = progress.get('model_state', {}).get('weights', [])
            self.all_results['final_weights'].append(weights)
            
            # ìˆ˜ë ´ ì •ë³´ (JSON ë°ì´í„°)
            convergence_info = progress.get('learning_status', {})
            self.all_results['convergence_episodes'].append(
                convergence_info.get('convergence_episode', -1)
            )
            self.all_results['is_converged'].append(
                convergence_info.get('is_converged', False)
            )
        
        # ì „ì²´ í†µê³„ ê³„ì‚°
        self.metrics['energy_savings_mean'] = np.mean(self.all_results['energy_savings'])
        self.metrics['energy_savings_std'] = np.std(self.all_results['energy_savings'])
        self.metrics['reward_mean'] = np.mean(self.all_results['avg_rewards'])
        self.metrics['reward_std'] = np.std(self.all_results['avg_rewards'])
        self.metrics['throughput_mean'] = np.mean(self.all_results['avg_throughputs'])
        self.metrics['throughput_std'] = np.std(self.all_results['avg_throughputs'])
        
        print(f"âœ… í‰ê·  ì—ë„ˆì§€ ì ˆê°ìœ¨: {self.metrics['energy_savings_mean']:.1f}% Â± {self.metrics['energy_savings_std']:.1f}%")
        print(f"âœ… í‰ê·  ë³´ìƒ: {self.metrics['reward_mean']:.4f} Â± {self.metrics['reward_std']:.4f}")
        print(f"âœ… í‰ê·  Throughput: {self.metrics['throughput_mean']:.1f} Â± {self.metrics['throughput_std']:.1f} Mbps")
    
            
            
    def calculate_statistics(self):
        """í†µê³„ ì§€í‘œ ê³„ì‚°"""
        # ì—ë„ˆì§€ ì ˆê°ìœ¨ í†µê³„
        if self.all_results['energy_savings']:
            self.metrics['energy_savings_mean'] = np.mean(self.all_results['energy_savings'])
            self.metrics['energy_savings_std'] = np.std(self.all_results['energy_savings'])
        else:
            self.metrics['energy_savings_mean'] = 0
            self.metrics['energy_savings_std'] = 0
        
        # í‰ê·  ë³´ìƒ
        if self.all_results['rewards']:
            all_rewards_flat = [r for rewards in self.all_results['rewards'] for r in rewards]
            if all_rewards_flat:
                self.metrics['reward_mean'] = np.mean(all_rewards_flat)
                self.metrics['reward_std'] = np.std(all_rewards_flat)
            else:
                self.metrics['reward_mean'] = 0
                self.metrics['reward_std'] = 0
        else:
            self.metrics['reward_mean'] = 0
            self.metrics['reward_std'] = 0
        
        # ì²˜ë¦¬ëŸ‰ í†µê³„
        if self.all_results['avg_throughput']:
            self.metrics['throughput_mean'] = np.mean(self.all_results['avg_throughput'])
            self.metrics['throughput_std'] = np.std(self.all_results['avg_throughput'])
        else:
            self.metrics['throughput_mean'] = 0
            self.metrics['throughput_std'] = 0
        
        print(f"\nğŸ“ˆ ì£¼ìš” ì§€í‘œ:")
        print(f"  - í‰ê·  ì—ë„ˆì§€ ì ˆê°ìœ¨: {self.metrics['energy_savings_mean']:.1f}% Â± {self.metrics['energy_savings_std']:.1f}%")
        print(f"  - í‰ê·  ë³´ìƒ: {self.metrics.get('reward_mean', 0):.4f} Â± {self.metrics.get('reward_std', 0):.4f}")
        if self.metrics.get('throughput_mean', 0) > 0:
            print(f"  - í‰ê·  ì²˜ë¦¬ëŸ‰: {self.metrics['throughput_mean']:.2f} Mbps Â± {self.metrics['throughput_std']:.2f}")
        
    def calculate_overall_regret(self):
        """ë©”íŠ¸ë¦­ ê³„ì‚° - ìˆ˜ì •ëœ ë²„ì „"""
        if not self.all_results['cumulative_regret']:
            print("âš ï¸ cumulative_regret ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë©”íŠ¸ë¦­ ê³„ì‚°ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return
        
        # ê° ì‹œë“œì˜ regret ë°ì´í„° ê¸¸ì´ í™•ì¸
        regret_lengths = [len(regret) for regret in self.all_results['cumulative_regret']]
        print(f"ê° ì‹œë“œì˜ regret ë°ì´í„° ê¸¸ì´: {regret_lengths}")
        
        if all(length == 0 for length in regret_lengths):
            print("âŒ ëª¨ë“  ì‹œë“œì˜ regret ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return
        
        # ëª¨ë“  ì‹œë“œì˜ ìµœëŒ€ ì—í”¼ì†Œë“œ ìˆ˜ ì°¾ê¸°
        max_episodes = max(regret_lengths)
        
        # í‰ê·  ëˆ„ì  í›„íšŒ ê³„ì‚°
        aligned_regrets = []
        for regret in self.all_results['cumulative_regret']:
            if len(regret) == 0:  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ëŠ” ê±´ë„ˆë›°ê¸°
                continue
            # ì§§ì€ ì‹œë“œëŠ” ë§ˆì§€ë§‰ ê°’ìœ¼ë¡œ íŒ¨ë”©
            if len(regret) < max_episodes:
                padded = regret + [regret[-1]] * (max_episodes - len(regret))
            else:
                padded = regret[:max_episodes]
            aligned_regrets.append(padded)
        
        if not aligned_regrets:
            print("âŒ ìœ íš¨í•œ regret ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        self.metrics['avg_cumulative_regret'] = np.mean(aligned_regrets, axis=0)
        self.metrics['std_cumulative_regret'] = np.std(aligned_regrets, axis=0)
        
        # í‰ê·  í›„íšŒ ê³„ì‚°
        self.metrics['avg_regret'] = self.metrics['avg_cumulative_regret'] / np.arange(1, max_episodes + 1)
        
        print(f"âœ… ë©”íŠ¸ë¦­ ê³„ì‚° ì™„ë£Œ: {max_episodes} ì—í”¼ì†Œë“œ")
    

    
    def save_summary(self):
        """ë¶„ì„ ìš”ì•½ ì €ì¥"""
        summary_file = self.output_dir / 'analysis_summary.txt'
        
        with open(summary_file, 'w') as f:
            f.write("EXP3 Multi-Seed Analysis Summary\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Results Directory: {self.results_dir}\n")
            f.write(f"Number of Seeds Analyzed: {len(self.seed_data)}\n\n")
            
            f.write("Key Performance Indicators:\n")
            f.write("-" * 30 + "\n")
            f.write(f"1. Energy Savings: {self.metrics['energy_savings_mean']:.1f}% Â± {self.metrics['energy_savings_std']:.1f}%\n")
            f.write(f"2. Average Reward: {self.metrics.get('reward_mean', 0):.4f} Â± {self.metrics.get('reward_std', 0):.4f}\n")
            if 'throughput_mean' in self.metrics:
                f.write(f"3. Average Throughput: {self.metrics['throughput_mean']:.2e} Mbps\n")
            if 'avg_regret' in self.metrics and len(self.metrics['avg_regret']) > 0:
                f.write(f"4. Final Average Regret: {self.metrics['avg_regret'][-1]:.4f}\n")
            
            f.write("\nSeed-wise Results:\n")
            f.write("-" * 30 + "\n")
            for seed_num in sorted(self.seed_data.keys())[:10]:  # ì²˜ìŒ 10ê°œë§Œ
                if seed_num < len(self.all_results['energy_savings']):
                    f.write(f"Seed {seed_num}: Energy Savings = {self.all_results['energy_savings'][seed_num]:.1f}%\n")
        
        # JSON í˜•ì‹ìœ¼ë¡œë„ ì €ì¥
        metrics_file = self.output_dir / 'analysis_metrics.json'
        save_metrics = {
            'summary': {
                'total_seeds': len(self.seed_data),
                'energy_savings_mean': self.metrics.get('energy_savings_mean', 0),
                'energy_savings_std': self.metrics.get('energy_savings_std', 0),
                'reward_mean': self.metrics.get('reward_mean', 0),
                'reward_std': self.metrics.get('reward_std', 0),
                'throughput_mean': self.metrics.get('throughput_mean', 0),
                'throughput_std': self.metrics.get('throughput_std', 0),
            },
            'timestamp': datetime.now().isoformat()
        }
        
        with open(metrics_file, 'w') as f:
            json.dump(save_metrics, f, indent=2)
        
        print(f"\nâœ… ë¶„ì„ ìš”ì•½ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
        print(f"   - {summary_file}")
        print(f"   - {metrics_file}")
 
 
    
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
import numpy as np
import pandas as pd
from scipy import stats
from collections import defaultdict

# ì „ì—­ ì„¤ì •
SEED_DISPLAY_COUNT = 10  # ëª¨ë“  ê·¸ë˜í”„ì—ì„œ í‘œì‹œí•  ì‹œë“œ ìˆ˜ í†µì¼
MOVING_AVG_WINDOW = 50  # ì´ë™í‰ê·  ì°½ í¬ê¸°

def plot_learning_curves(self, save_dir):
    """í•™ìŠµ ê³¡ì„  ê·¸ë¦¬ê¸° - ê°œì„ ëœ ë²„ì „"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. ë³´ìƒ íˆìŠ¤í† ë¦¬ with EMA
    ax = axes[0, 0]
    for seed_num, data in list(self.seed_data.items())[:SEED_DISPLAY_COUNT]:
        rewards = data['progress'].get('reward_history', [])
        if rewards:
            # ì´ë™í‰ê· 
            window = MOVING_AVG_WINDOW
            if len(rewards) > window:
                moving_avg = np.convolve(rewards, np.ones(window)/window, mode='valid')
                ax.plot(moving_avg, label=f'Seed {seed_num}', alpha=0.7)
    
    ax.set_xlabel('Episode')
    ax.set_ylabel(f'Reward (MA window={MOVING_AVG_WINDOW})')
    ax.set_title('Reward Learning Curves')
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', ncol=2)
    ax.grid(True, alpha=0.3)
    
    # 2. ì—ë„ˆì§€ ì ˆê°ìœ¨ with EMA
    ax = axes[0, 1]
    all_energy_data = []
    
    for seed_num, data in list(self.seed_data.items())[:SEED_DISPLAY_COUNT]:
        energy_savings = data['progress'].get('energy_saving_history', [])
        if energy_savings:
            # ì›ë³¸ ë°ì´í„° (íˆ¬ëª…í•˜ê²Œ)
            ax.plot(energy_savings, alpha=0.3, color='gray')
            
            # EMA (Exponential Moving Average)
            ema_alpha = 2 / (MOVING_AVG_WINDOW + 1)
            ema = pd.Series(energy_savings).ewm(alpha=ema_alpha, adjust=False).mean()
            ax.plot(ema, label=f'Seed {seed_num}', linewidth=2)
            all_energy_data.append(energy_savings)
    
    # ëª©í‘œ ë°´ë“œ ì¶”ê°€ (9-10% ì˜ˆì‹œ)
    ax.axhspan(9, 10, alpha=0.2, color='green', label='Target Band')
    ax.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    
    ax.set_xlabel('Episode')
    ax.set_ylabel('Energy Saving (%)')
    ax.set_title('Energy Saving Over Time (with EMA)')
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', ncol=2)
    ax.grid(True, alpha=0.3)
    
    # 3. ëˆ„ì  í›„íšŒ with 95% CI
    ax = axes[1, 0]
    all_cumulative_regrets = []
    
    for seed_num, data in list(self.seed_data.items())[:SEED_DISPLAY_COUNT]:
        cumulative_regret = data['progress'].get('cumulative_regret_history', [])
        if cumulative_regret:
            episodes = range(1, len(cumulative_regret) + 1)
            ax.plot(episodes, cumulative_regret, alpha=0.3, color='blue')
            all_cumulative_regrets.append(cumulative_regret)
    
    if all_cumulative_regrets:
        # í‰ê· ê³¼ 95% CI ê³„ì‚°
        min_length = min(len(cr) for cr in all_cumulative_regrets)
        truncated_regrets = np.array([cr[:min_length] for cr in all_cumulative_regrets])
        mean_regret = np.mean(truncated_regrets, axis=0)
        std_regret = np.std(truncated_regrets, axis=0)
        ci_95 = 1.96 * std_regret / np.sqrt(len(all_cumulative_regrets))
        
        episodes = range(1, len(mean_regret) + 1)
        ax.plot(episodes, mean_regret, 'k-', linewidth=2, label='Mean')
        ax.fill_between(episodes, mean_regret - ci_95, mean_regret + ci_95, 
                        alpha=0.3, color='gray', label='95% CI')
        
        # ì´ë¡ ì  O(âˆšT) ê°€ì´ë“œë¼ì¸
        n_arms = 969  # EXP3ì˜ arm ìˆ˜
        theoretical_bound = 2 * np.sqrt(np.arange(1, len(mean_regret) + 1) * n_arms * np.log(n_arms))
        ax.plot(episodes, theoretical_bound, 'r--', label=r'$O(\sqrt{T})$ bound', alpha=0.7)
    
    ax.set_xlabel('Episode')
    ax.set_ylabel('Cumulative Regret')
    ax.set_title('Cumulative Regret with 95% CI')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 4. Throughput with SLA
    ax = axes[1, 1]
    for seed_num, data in list(self.seed_data.items())[:SEED_DISPLAY_COUNT]:
        throughput = data['progress'].get('throughput_history', [])
        if throughput:
            window = MOVING_AVG_WINDOW
            if len(throughput) > window:
                moving_avg = np.convolve(throughput, np.ones(window)/window, mode='valid')
                ax.plot(moving_avg, label=f'Seed {seed_num}', alpha=0.7)
    
    # SLA ê¸°ì¤€ì„  (ì˜ˆ: 300 Mbps)
    ax.axhline(y=300, color='red', linestyle='--', label='SLA (300 Mbps)', linewidth=2)
    
    ax.set_xlabel('Episode')
    ax.set_ylabel(f'Throughput (Mbps, MA window={MOVING_AVG_WINDOW})')
    ax.set_title('Network Throughput')
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', ncol=2)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_dir / 'learning_curves_improved.png', dpi=300, bbox_inches='tight')
    plt.close()

    def plot_regret_analysis(self, save_dir):
        """í›„íšŒ(regret) ë¶„ì„ í”Œë¡¯ - ê°œì„ ëœ ë²„ì „"""
        fig, axes = plt.subplots(2, 3, figsize=(15, 8))
        fig.suptitle('EXP3 Regret Analysis Across Seeds', fontsize=16)
        
        # 1. ëˆ„ì  regret ë¹„êµ
        ax = axes[0, 0]
        for seed_num, data in list(self.seed_data.items())[:SEED_DISPLAY_COUNT]:
            cumulative_regret = data['progress'].get('cumulative_regret_history', [])
            if cumulative_regret:
                episodes = range(1, len(cumulative_regret) + 1)
                ax.plot(episodes, cumulative_regret, alpha=0.6)
        
        ax.set_xlabel('Episode')
        ax.set_ylabel('Cumulative Regret')
        ax.set_title('Cumulative Regret Comparison')
        ax.grid(True, alpha=0.3)
        
        # 2. í‰ê·  regret (ì„ í˜• ìŠ¤ì¼€ì¼)
        ax = axes[0, 1]
        all_avg_regrets = []
        for seed_num, data in list(self.seed_data.items())[:SEED_DISPLAY_COUNT]:
            cumulative_regret = data['progress'].get('cumulative_regret_history', [])
            if cumulative_regret:
                avg_regret = [cumulative_regret[i] / (i + 1) for i in range(len(cumulative_regret))]
                ax.plot(avg_regret, alpha=0.6)
                all_avg_regrets.append(avg_regret)
        
        ax.set_xlabel('Episode')
        ax.set_ylabel('Average Regret')
        ax.set_title('Average Regret (Linear Scale)')
        ax.grid(True, alpha=0.3)
        
        # 3. í‰ê·  regret (ë¡œê·¸ ìŠ¤ì¼€ì¼)
        ax = axes[0, 2]
        for avg_regret in all_avg_regrets:
            ax.semilogy(avg_regret, alpha=0.6)
        
        ax.set_xlabel('Episode')
        ax.set_ylabel('Average Regret (log scale)')
        ax.set_title('Average Regret (Log Scale)')
        ax.grid(True, alpha=0.3)
        
        # 4. ìµœì¢… regret ë¶„í¬ (ê°œì„ ëœ bin)
        ax = axes[1, 0]
        final_regrets = []
        for data in self.seed_data.values():
            cum_regret = data['progress'].get('cumulative_regret_history', [])
            if cum_regret:
                final_regrets.append(cum_regret[-1])
        
        if final_regrets:
            # Freedman-Diaconis rule for bin width
            q75, q25 = np.percentile(final_regrets, [75, 25])
            iqr = q75 - q25
            bin_width = 2 * iqr / (len(final_regrets) ** (1/3))
            n_bins = int((max(final_regrets) - min(final_regrets)) / bin_width)
            n_bins = max(n_bins, 10)  # ìµœì†Œ 10ê°œ bin
            
            ax.hist(final_regrets, bins=n_bins, edgecolor='black', alpha=0.7)
            ax.axvline(np.mean(final_regrets), color='red', linestyle='--', 
                    label=f'Mean: {np.mean(final_regrets):.2f}')
            ax.axvline(np.median(final_regrets), color='green', linestyle='--', 
                    label=f'Median: {np.median(final_regrets):.2f}')
        
        ax.set_xlabel('Final Cumulative Regret')
        ax.set_ylabel('Frequency')
        ax.set_title('Distribution of Final Regret')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 5. Regret ë¹„ìœ¨ (ëª¨ë“  ì‹œë“œ)
        ax = axes[1, 1]
        regret_ratios = []
        seeds = []
        
        for seed_num, data in self.seed_data.items():
            regret_stats = data['progress'].get('performance_summary', {}).get('regret_statistics', {})
            regret_ratio = regret_stats.get('regret_ratio', 0)
            if regret_ratio > 0:
                regret_ratios.append(regret_ratio)
                seeds.append(seed_num)
        
        if regret_ratios:
            ax.scatter(seeds, regret_ratios, s=50, alpha=0.6)
            
            # í‰ê· ê³¼ í‘œì¤€í¸ì°¨
            mean_ratio = np.mean(regret_ratios)
            std_ratio = np.std(regret_ratios)
            ax.axhline(y=mean_ratio, color='blue', linestyle='-', alpha=0.5, 
                    label=f'Mean: {mean_ratio:.4f}')
            ax.fill_between(seeds, mean_ratio - std_ratio, mean_ratio + std_ratio, 
                            alpha=0.2, color='blue', label=f'Â±1 STD')
        
        ax.axhline(y=1.0, color='red', linestyle='--', alpha=0.5, label='Theoretical Limit')
        ax.set_xlabel('Seed Number')
        ax.set_ylabel('Regret Ratio (Actual/Theoretical)')
        ax.set_title('Regret Ratio - All Seeds')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 6. ë¹ˆ í”Œë¡¯ ì²˜ë¦¬
        ax = axes[1, 2]
        ax.text(0.5, 0.5, 'Additional Analysis\n(Reserved)', 
                ha='center', va='center', transform=ax.transAxes,
                fontsize=12, bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))
        ax.axis('off')
        
        plt.tight_layout()
        plt.savefig(save_dir / 'regret_analysis_improved.png', dpi=300, bbox_inches='tight')
        plt.close()

    def plot_energy_throughput_comparison(self, save_dir):
        """ì—ë„ˆì§€-ì²˜ë¦¬ëŸ‰ ë¹„êµ í”Œë¡¯ - ê°œì„ ëœ ë²„ì „"""
        fig, axes = plt.subplots(1, 2, figsize=(12, 5))
        
        # 1. ì—ë„ˆì§€ ì ˆê° vs Throughput ì‚°ì ë„ with íšŒê·€ë¶„ì„
        ax = axes[0]
        energy_savings_final = []
        throughput_final = []
        
        for seed_num, data in self.seed_data.items():
            energy_history = data['progress'].get('energy_saving_history', [])
            throughput_history = data['progress'].get('throughput_history', [])
            
            if energy_history and throughput_history:
                final_energy = np.mean(energy_history[-100:])
                final_throughput = np.mean(throughput_history[-100:])
                
                energy_savings_final.append(final_energy)
                throughput_final.append(final_throughput)
                
                ax.scatter(final_energy, final_throughput, s=50, alpha=0.6)
        
        if energy_savings_final and throughput_final:
            # í‰ê· ì  í‘œì‹œ
            ax.scatter(np.mean(energy_savings_final), np.mean(throughput_final), 
                    s=200, c='red', marker='*', label='Average', zorder=5)
            
            # íšŒê·€ì„ ê³¼ ìƒê´€ê³„ìˆ˜
            slope, intercept, r_value, p_value, std_err = stats.linregress(energy_savings_final, throughput_final)
            line_x = np.array([min(energy_savings_final), max(energy_savings_final)])
            line_y = slope * line_x + intercept
            ax.plot(line_x, line_y, 'r--', alpha=0.8)
            
            # ìƒê´€ê³„ìˆ˜ì™€ pê°’ í‘œì‹œ
            ax.text(0.05, 0.95, f'r = {r_value:.3f}\np = {p_value:.3f}', 
                    transform=ax.transAxes, verticalalignment='top',
                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        ax.set_xlabel('Energy Saving (%)')
        ax.set_ylabel('Throughput (Mbps)')
        ax.set_title('Energy Saving vs Throughput Trade-off')
        ax.grid(True, alpha=0.3)
        ax.legend()
        
        # 2. ì‹œê°„ì— ë”°ë¥¸ íš¨ìœ¨ì„± ë³€í™” with í‰í˜• êµ¬ê°„ ê°•ì¡°
        ax = axes[1]
        for seed_num, data in list(self.seed_data.items())[:SEED_DISPLAY_COUNT]:
            efficiency_history = data['progress'].get('efficiency_history', [])
            if efficiency_history:
                # EMA ì ìš©
                ema_alpha = 2 / (MOVING_AVG_WINDOW + 1)
                ema = pd.Series(efficiency_history).ewm(alpha=ema_alpha, adjust=False).mean()
                ax.plot(ema, label=f'Seed {seed_num}', alpha=0.7)
                
                # ë§ˆì§€ë§‰ 20% êµ¬ê°„ ê°•ì¡°
                last_20_percent = int(len(efficiency_history) * 0.8)
                ax.axvspan(last_20_percent, len(efficiency_history), 
                        alpha=0.1, color='gray', label='Equilibrium Region' if seed_num == 0 else "")
        
        ax.set_xlabel('Episode')
        ax.set_ylabel(f'Efficiency (bits/J, EMA Î±={ema_alpha:.3f})')
        ax.set_title('Network Efficiency Evolution')
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', ncol=2)
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_dir / 'energy_throughput_comparison_improved.png', dpi=300, bbox_inches='tight')
        plt.close()

    def plot_convergence_analysis(self, save_dir):
        """ìˆ˜ë ´ ë¶„ì„ ê·¸ë˜í”„ - ê°œì„ ëœ ë²„ì „"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        
        # 1. ê°€ì¤‘ì¹˜ ìƒëŒ€ ì—”íŠ¸ë¡œí”¼ (KL divergence to uniform)
        ax = axes[0, 0]
        ax.yaxis.set_major_formatter(ticker.ScalarFormatter(useOffset=False))
        
        weight_kl_divergences = []
        seed_numbers = []
        
        for seed_num, data in self.seed_data.items():
            weights = data['model'].get('weights', [])
            if not weights:
                weights = data['progress'].get('model_state', {}).get('weights', [])
            
            if weights:
                weights_array = np.array(weights)
                # ì •ê·œí™”
                weights_norm = weights_array / (weights_array.sum() + 1e-10)
                # ê· ë“±ë¶„í¬
                uniform_dist = np.ones(len(weights)) / len(weights)
                # KL divergence
                kl_div = np.sum(weights_norm * np.log(weights_norm / uniform_dist + 1e-10))
                weight_kl_divergences.append(kl_div)
                seed_numbers.append(seed_num)
        
        if weight_kl_divergences:
            ax.scatter(seed_numbers, weight_kl_divergences, s=50)
            ax.axhline(y=0, color='red', linestyle='--', alpha=0.5, label='Uniform (KL=0)')
        
        ax.set_xlabel('Seed Number')
        ax.set_ylabel('KL Divergence from Uniform')
        ax.set_title('Weight Distribution Concentration')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 2. ìˆ˜ë ´ ì—í”¼ì†Œë“œ ë¶„í¬ ë˜ëŠ” N/A
        ax = axes[0, 1]
        converged_episodes = []
        
        for data in self.seed_data.values():
            conv_ep = data['progress'].get('learning_status', {}).get('convergence_episode', -1)
            if conv_ep > 0:
                converged_episodes.append(conv_ep)
        
        if converged_episodes:
            ax.hist(converged_episodes, bins=20, edgecolor='black', alpha=0.7)
            ax.axvline(np.mean(converged_episodes), color='red', linestyle='--',
                    label=f'Mean: {np.mean(converged_episodes):.0f}')
            ax.set_xlabel('Convergence Episode')
            ax.set_ylabel('Frequency')
            ax.legend()
        else:
            ax.text(0.5, 0.5, 'No Convergence Detected\n(Criterion may be too strict)', 
                    ha='center', va='center', transform=ax.transAxes,
                    fontsize=12, bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.5))
        
        ax.set_title(f'Convergence Episodes (Ï„={0.01}, M={50})')
        ax.grid(True, alpha=0.3)
        
        # 3. ìµœì  arm ì„ íƒ ë¹ˆë„ - ê°œì„ ëœ ì‹œê°í™”
        ax = axes[1, 0]
        best_arms = []
        for data in self.seed_data.values():
            best_arm_info = data['progress'].get('best_arm', {})
            best_arm_idx = best_arm_info.get('index', -1)
            if best_arm_idx >= 0:
                best_arms.append(best_arm_idx)
        
        if best_arms:
            unique_arms, counts = np.unique(best_arms, return_counts=True)
            # ê°€ì¥ ë§ì´ ì„ íƒëœ arm
            most_common_idx = np.argmax(counts)
            most_common_arm = unique_arms[most_common_idx]
            most_common_count = counts[most_common_idx]
            
            # ë¹ˆë„ë³„ ìƒ‰ìƒ
            colors = ['red' if arm == most_common_arm else 'blue' for arm in unique_arms]
            ax.bar(range(len(unique_arms)), counts, color=colors, alpha=0.7)
            
            ax.set_xlabel('Best Arm Index')
            ax.set_ylabel('Frequency')
            ax.set_title(f'Best Arm Distribution (Most common: Arm {most_common_arm}, {most_common_count}/{len(self.seed_data)} seeds)')
            ax.grid(True, alpha=0.3)
        
        # 4. ìµœì¢… ì„±ëŠ¥ ë¶„í¬ with baseline
        ax = axes[1, 1]
        final_rewards = []
        for data in self.seed_data.values():
            reward_history = data['progress'].get('reward_history', [])
            if reward_history:
                final_avg_reward = np.mean(reward_history[-100:])
                final_rewards.append(final_avg_reward)
        
        if final_rewards:
            bp = ax.boxplot(final_rewards, patch_artist=True)
            bp['boxes'][0].set_facecolor('lightblue')
            
            # ë¬´ì‘ìœ„ ì„ íƒ baseline (ì˜ˆì‹œê°’)
            random_baseline = 0.3
            ax.axhline(y=random_baseline, color='red', linestyle='--', 
                    label=f'Random baseline ({random_baseline:.3f})')
            
            ax.set_ylabel('Final Average Reward')
            ax.set_title('Final Performance Distribution')
            ax.set_ylim(bottom=0.25, top=max(final_rewards) * 1.1)
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_dir / 'convergence_analysis_improved.png', dpi=300, bbox_inches='tight')
        plt.close()

    def plot_performance_distribution(self, save_dir):
        """ì„±ëŠ¥ ë¶„í¬ ë¶„ì„ - ê°œì„ ëœ ë²„ì „"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 8))
        
        # ëª¨ë“  íŒ¨ë„ì— ëŒ€í•´ ë™ì¼í•œ ì²˜ë¦¬
        metrics = [
            ('energy_saving_history', 'Energy Saving (%)', axes[0, 0]),
            ('throughput_history', 'Throughput (Mbps)', axes[0, 1]),
            ('reward_history', 'Reward', axes[1, 0]),
            ('efficiency_history', 'Efficiency (bits/J)', axes[1, 1])
        ]
        
        for metric_name, ylabel, ax in metrics:
            all_values = []
            ema_values = []  # EMA ê¸°ë°˜ ê°’
            
            for data in self.seed_data.values():
                history = data['progress'].get(metric_name, [])
                if history:
                    # ë§ˆì§€ë§‰ 20% ë°ì´í„°
                    final_portion = history[int(len(history)*0.8):]
                    all_values.extend(final_portion)
                    
                    # EMA ê¸°ë°˜ ìµœì¢…ê°’
                    ema_alpha = 0.1
                    ema = pd.Series(history).ewm(alpha=ema_alpha, adjust=False).mean()
                    ema_values.append(ema.iloc[-1])
            
            if all_values:
                # íˆìŠ¤í† ê·¸ë¨
                ax.hist(all_values, bins=50, density=True, alpha=0.5, edgecolor='black', 
                        label='Raw (last 20%)')
                
                # EMA ë¶„í¬
                if ema_values:
                    ax.hist(ema_values, bins=20, density=True, alpha=0.7, 
                            edgecolor='red', color='red', label='EMA final')
                
                # í†µê³„ê°’
                mean_val = np.mean(all_values)
                median_val = np.median(all_values)
                ax.axvline(mean_val, color='red', linestyle='--', linewidth=2)
                ax.axvline(median_val, color='green', linestyle='--', linewidth=2)
                
                # ì§§ì€ í…ìŠ¤íŠ¸ í‘œê¸°
                ax.text(0.02, 0.98, f'Î¼={mean_val:.1f}\nM={median_val:.1f}', 
                        transform=ax.transAxes, verticalalignment='top',
                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
            
            ax.set_xlabel(ylabel)
            ax.set_ylabel('Density')
            ax.set_title(f'Distribution of {ylabel.split(" ")[0]}')
            ax.legend(loc='upper right')
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_dir / 'performance_distribution_improved.png', dpi=300, bbox_inches='tight')
        plt.close()

    def plot_arm_selection_frequency(self, save_dir):
        """Arm ì„ íƒ ë¹ˆë„ ë¶„ì„ - ê°œì„ ëœ ë²„ì „"""
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # 1. ìƒìœ„ arm ì„ íƒ ë¹ˆë„ - ê°€ë¡œ ë§‰ëŒ€ ê·¸ë˜í”„
        ax = axes[0]
        
        total_arm_counts = defaultdict(int)
        for data in self.seed_data.values():
            arm_counts = data['progress'].get('model_state', {}).get('arm_selection_count', [])
            if arm_counts:
                for i, count in enumerate(arm_counts):
                    total_arm_counts[i] += count
        
        if total_arm_counts:
            # ìƒìœ„ 20ê°œ arm
            sorted_arms = sorted(total_arm_counts.items(), key=lambda x: x[1], reverse=True)[:20]
            arms, counts = zip(*sorted_arms)
            
            y_pos = np.arange(len(arms))
            bars = ax.barh(y_pos, counts, alpha=0.7, color='steelblue')
            
            # ê°’ ë¼ë²¨ í‘œì‹œ
            for i, (bar, count) in enumerate(zip(bars, counts)):
                ax.text(bar.get_width() + max(counts)*0.01, bar.get_y() + bar.get_height()/2, 
                        f'{count}', ha='left', va='center')
            
            ax.set_yticks(y_pos)
            ax.set_yticklabels([f'Arm {arm}' for arm in arms])
            ax.set_xlabel('Total Selection Count')
            ax.set_title('Top 20 Arms by Selection Frequency')
            ax.grid(True, alpha=0.3, axis='x')
        
        # 2. ì‹œë“œë³„ ìµœì  armì˜ ì¼ê´€ì„± - jitter ì ìš©
        ax = axes[1]
        
        seed_best_arms = []
        for seed_num, data in self.seed_data.items():
            best_arm = data['progress'].get('best_arm', {}).get('index', -1)
            if best_arm >= 0:
                seed_best_arms.append((seed_num, best_arm))
        
        if seed_best_arms:
            seeds, best_arms = zip(*seed_best_arms)
            
            # Jitter ì¶”ê°€
            jitter = np.random.normal(0, 0.1, len(seeds))
            ax.scatter(np.array(seeds) + jitter, best_arms, s=50, alpha=0.6)
            
            # ê°€ì¥ ë§ì´ ì„ íƒëœ best arm
            unique_best, counts = np.unique(best_arms, return_counts=True)
            most_common_arm = unique_best[np.argmax(counts)]
            most_common_count = counts[np.argmax(counts)]
            
            ax.axhline(y=most_common_arm, color='red', linestyle='--', 
                    label=f'Most Common: Arm {most_common_arm}')
            
            ax.set_xlabel('Seed Number')
            ax.set_ylabel('Best Arm Index')
            ax.set_title(f'Best Arm Selection Across Seeds\n(Most common: Arm {most_common_arm}, {most_common_count}/{len(self.seed_data)} seeds)')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_dir / 'arm_selection_frequency_improved.png', dpi=300, bbox_inches='tight')
        plt.close()

    def plot_final_performance_summary(self, save_dir):
        """ìµœì¢… ì„±ëŠ¥ ìš”ì•½ í”Œë¡¯ - ê°œì„ ëœ ë²„ì „"""
        fig = plt.figure(figsize=(16, 10))
        gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)
        
        # 1. ì£¼ìš” ì§€í‘œ ë°•ìŠ¤í”Œë¡¯ (ë‹¨ìœ„ í†µì¼)
        ax1 = fig.add_subplot(gs[0, :2])
        
        metrics_data = []
        metric_labels = []
        
        # ì—ë„ˆì§€ ì ˆê°ë¥ 
        energy_savings = []
        for data in self.seed_data.values():
            energy_history = data['progress'].get('energy_saving_history', [])
            if energy_history:
                energy_savings.append(np.mean(energy_history[-100:]))
        if energy_savings:
            metrics_data.append(energy_savings)
            metric_labels.append('Energy\nSaving (%)')
        
        # í‰ê·  ë³´ìƒ
        avg_rewards = []
        for data in self.seed_data.values():
            reward_history = data['progress'].get('reward_history', [])
            if reward_history:
                avg_rewards.append(np.mean(reward_history[-100:]))
        if avg_rewards:
            metrics_data.append(avg_rewards)
            metric_labels.append('Average\nReward')
        
        # Throughput (Mbpsë¡œ í†µì¼)
        avg_throughputs = []
        for data in self.seed_data.values():
            throughput_history = data['progress'].get('throughput_history', [])
            if throughput_history:
                avg_throughputs.append(np.mean(throughput_history[-100:]))
        if avg_throughputs:
            metrics_data.append(avg_throughputs)
            metric_labels.append('Throughput\n(Mbps)')
        
        if metrics_data:
            bp = ax1.boxplot(metrics_data, labels=metric_labels, patch_artist=True)
            for patch in bp['boxes']:
                patch.set_facecolor('lightblue')
            ax1.set_title('Performance Metrics Distribution', fontsize=14)
            ax1.grid(True, alpha=0.3)
        
        # 2. ìˆ˜ë ´ í†µê³„ with ê¸°ì¤€ í‘œì‹œ
        ax2 = fig.add_subplot(gs[0, 2])
        
        convergence_stats = {'Converged': 0, 'Not Converged': 0}
        for data in self.seed_data.values():
            is_converged = data['progress'].get('learning_status', {}).get('is_converged', False)
            if is_converged:
                convergence_stats['Converged'] += 1
            else:
                convergence_stats['Not Converged'] += 1
        
        if sum(convergence_stats.values()) > 0:
            colors = ['green', 'red']
            ax2.pie(convergence_stats.values(), labels=convergence_stats.keys(), 
                    autopct='%1.1f%%', startangle=90, colors=colors)
            ax2.set_title(f'Convergence Status\n(Ï„=0.01, M=50 steps)', fontsize=14)
        
        # 3. ì„±ëŠ¥ vs ì—ë„ˆì§€ ì ˆê° ì‚°ì ë„ with r, p
        ax3 = fig.add_subplot(gs[1, 0])
        
        if energy_savings and avg_rewards:
            ax3.scatter(energy_savings, avg_rewards, s=100, alpha=0.6, 
                        c=range(len(energy_savings)), cmap='viridis')
            ax3.set_xlabel('Energy Saving (%)')
            ax3.set_ylabel('Average Reward')
            ax3.set_title('Energy-Performance Trade-off', fontsize=14)
            ax3.grid(True, alpha=0.3)
            
            # ì¶”ì„¸ì„ ê³¼ í†µê³„
            if len(energy_savings) > 3:
                slope, intercept, r_value, p_value, _ = stats.linregress(energy_savings, avg_rewards)
                line_x = np.array([min(energy_savings), max(energy_savings)])
                line_y = slope * line_x + intercept
                ax3.plot(line_x, line_y, "r--", alpha=0.8)
                
                # r, p ê°’ í‘œì‹œ
                ax3.text(0.95, 0.95, f'r = {r_value:.3f}\np = {p_value:.3f}', 
                        transform=ax3.transAxes, ha='right', va='top',
                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
        
        # 4. ìµœì¢… Regret ë¶„í¬
        ax4 = fig.add_subplot(gs[1, 1])
        
        final_regrets = []
        for data in self.seed_data.values():
            regret_history = data['progress'].get('cumulative_regret_history', [])
            if regret_history:
                final_regrets.append(regret_history[-1])
        
        if final_regrets:
            ax4.hist(final_regrets, bins=20, edgecolor='black', alpha=0.7, color='orange')
            ax4.axvline(np.mean(final_regrets), color='red', linestyle='--', 
                        label=f'Mean: {np.mean(final_regrets):.1f}')
            ax4.set_xlabel('Final Cumulative Regret')
            ax4.set_ylabel('Frequency')
            ax4.set_title('Final Regret Distribution', fontsize=14)
            ax4.legend()
            ax4.grid(True, alpha=0.3)
        
        # 5. í†µê³„ ìš”ì•½ í…Œì´ë¸” (í˜•ì‹ í†µì¼)
        ax5 = fig.add_subplot(gs[1, 2])
        ax5.axis('off')
        
        summary_stats = []
        summary_stats.append(['Metric', 'Mean Â± Std'])
        summary_stats.append(['', ''])
        
        if energy_savings:
            summary_stats.append(['Energy Saving (%)', f'{np.mean(energy_savings):.1f} Â± {np.std(energy_savings):.1f}'])
        if avg_rewards:
            summary_stats.append(['Avg Reward', f'{np.mean(avg_rewards):.4f} Â± {np.std(avg_rewards):.4f}'])
        if avg_throughputs:
            summary_stats.append(['Throughput (Mbps)', f'{np.mean(avg_throughputs):.1f} Â± {np.std(avg_throughputs):.1f}'])
        if final_regrets:
            summary_stats.append(['Final Regret', f'{np.mean(final_regrets):.1f} Â± {np.std(final_regrets):.1f}'])
        
        summary_stats.append(['', ''])
        summary_stats.append(['Total Seeds (N)', str(len(self.seed_data))])
        summary_stats.append(['Converged', f'{convergence_stats["Converged"]}/{len(self.seed_data)}'])
        summary_stats.append(['Episodes (T)', str(data['progress'].get('episode', 0))])
        summary_stats.append(['MA Window', str(MOVING_AVG_WINDOW)])
        
        # í…Œì´ë¸” ìƒì„±
        table = ax5.table(cellText=summary_stats, loc='center', cellLoc='left')
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1.2, 1.5)
        
        # í—¤ë” ìŠ¤íƒ€ì¼
        for i in range(len(summary_stats[0])):
            table[(0, i)].set_facecolor('#4CAF50')
            table[(0, i)].set_text_props(weight='bold', color='white')
        
        ax5.set_title('Summary Statistics', fontsize=14, pad=20)
        
        # ì „ì²´ ì œëª©
        fig.suptitle('EXP3 Multi-Seed Analysis Summary', fontsize=16, y=0.98)
        
        plt.tight_layout()
        plt.savefig(save_dir / 'final_performance_summary_improved.png', dpi=300, bbox_inches='tight')
        plt.close()
    def plot_all_results(self):
        """ëª¨ë“  ê²°ê³¼ í”Œë¡¯ ìƒì„±"""
        print("\nğŸ“Š ê²°ê³¼ ì‹œê°í™” ì¤‘...")
        
        # ë¶„ì„ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
        plots_dir = self.output_dir / 'plots'
        plots_dir.mkdir(exist_ok=True)
        
        # ê° í”Œë¡¯ ìƒì„±
        self.plot_learning_curves(plots_dir)
        self.plot_regret_analysis(plots_dir)
        self.plot_energy_throughput_comparison(plots_dir)
        self.plot_convergence_analysis(plots_dir)
        self.plot_performance_distribution(plots_dir)
        self.plot_arm_selection_frequency(plots_dir)
        self.plot_final_performance_summary(plots_dir)   
        
    def run_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print("\nğŸš€ EXP3 ë‹¤ì¤‘ ì‹œë“œ ë¶„ì„ ì‹œì‘...")
        print("=" * 60)
        
        # 1. ëª¨ë“  ì‹œë“œ ë°ì´í„° ë¡œë“œ
        if not self.load_all_seeds():
            print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            return
        
        # 2. ì„±ëŠ¥ ë¶„ì„
        self.analyze_performance()
        
        # 3. í›„íšŒ ë¶„ì„
        self.calculate_overall_regret()
        
        # 4. ê²°ê³¼ ì‹œê°í™”
        self.plot_all_results()
        
        # 5. ìš”ì•½ ì €ì¥
        self.save_summary()
        
        print("\n" + "=" * 60)
        print("âœ… ë¶„ì„ ì™„ë£Œ!")


def run_analysis_integrated(config_file, output_base_dir="data/output", current_run_timestamp=None):
    """
    ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ë¶„ì„ í•¨ìˆ˜
    
    Args:
        config_file (str): ì‚¬ìš©ëœ ì„¤ì • íŒŒì¼ ê²½ë¡œ
        output_base_dir (str): ì¶œë ¥ ê¸°ë³¸ ë””ë ‰í† ë¦¬
        current_run_timestamp (str): í˜„ì¬ ì‹¤í–‰ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ (YYYY_MM_DD/HHMMSS í˜•ì‹)
    """
    print("\n" + "="*60)
    print("ğŸ”¬ EXP3 ì‹¤í—˜ ê²°ê³¼ ìë™ ë¶„ì„ ì‹œì‘...")
    print("="*60)
    
    # ì„¤ì • íŒŒì¼ì—ì„œ ì‹¤í—˜ ì´ë¦„ ì¶”ì¶œ
    with open(config_file, 'r') as f:
        config = json.load(f)
    
    experiment_name = config.get('experiment_description', 'exp3_experiment')
    
    # í˜„ì¬ ì‹¤í–‰ì˜ ê²°ê³¼ ë””ë ‰í† ë¦¬ ì§€ì •
    if current_run_timestamp:
        # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹±
        date_part, time_part = current_run_timestamp.split('/')
        results_dir = Path(output_base_dir) / experiment_name / date_part / time_part
    else:
        # ìµœì‹  ì‹¤í–‰ ì°¾ê¸°
        exp_dir = Path(output_base_dir) / experiment_name
        if not exp_dir.exists():
            print(f"âŒ ì‹¤í—˜ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {exp_dir}")
            return
        
        # ìµœì‹  ë‚ ì§œ/ì‹œê°„ ì°¾ê¸°
        latest_date = sorted([d for d in exp_dir.iterdir() if d.is_dir()], reverse=True)[0]
        latest_time = sorted([t for t in latest_date.iterdir() if t.is_dir()], reverse=True)[0]
        results_dir = latest_time
    
    print(f"ğŸ“ ë¶„ì„ ëŒ€ìƒ ë””ë ‰í† ë¦¬: {results_dir}")
    
    # ë¶„ì„ê¸° ì‹¤í–‰
    analyzer = EXP3MultiSeedAnalyzer(
        results_dir=results_dir,
        config_file=config_file
    )
    
    try:
        analyzer.run_analysis()
    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


def main():
    """ë…ë¦½ ì‹¤í–‰ìš© main í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="EXP3 ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ ê²°ê³¼ ë¶„ì„",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
                ì‚¬ìš© ì˜ˆì‹œ:
                # íŠ¹ì • ì‹¤í–‰ ê²°ê³¼ ë¶„ì„
                python exp3_analysis.py --results_dir data/output/exp3_cell_optimization_training_fixed/2025_07_17/120233
                
                # ìµœì‹  ê²°ê³¼ ìë™ ì°¾ê¸°
                python exp3_analysis.py --experiment_name exp3_cell_optimization_training_fixed
                        """
    )
    
    parser.add_argument(
        '--results_dir',
        type=str,
        help='ê²°ê³¼ê°€ ìˆëŠ” ì •í™•í•œ ë””ë ‰í† ë¦¬ ê²½ë¡œ'
    )
    
    parser.add_argument(
        '--experiment_name',
        type=str,
        help='ì‹¤í—˜ ì´ë¦„ (ìµœì‹  ê²°ê³¼ ìë™ ì°¾ê¸°)'
    )
    
    parser.add_argument(
        '--output_base_dir',
        type=str,
        default='data/output',
        help='ì¶œë ¥ ê¸°ë³¸ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: data/output)'
    )
    
    args = parser.parse_args()
    
    if args.results_dir:
        # ì§ì ‘ ì§€ì •ëœ ë””ë ‰í† ë¦¬ ë¶„ì„
        analyzer = EXP3MultiSeedAnalyzer(results_dir=args.results_dir)
        analyzer.run_analysis()
    elif args.experiment_name:
        # ìµœì‹  ê²°ê³¼ ì°¾ì•„ì„œ ë¶„ì„
        run_analysis_integrated(
            config_file=None,  # ë…ë¦½ ì‹¤í–‰ì‹œì—ëŠ” config íŒŒì¼ ì—†ì–´ë„ ë¨
            output_base_dir=args.output_base_dir,
            current_run_timestamp=None  # ìµœì‹  ì°¾ê¸°
        )
    else:
        parser.print_help()
        print("\nâŒ --results_dir ë˜ëŠ” --experiment_name ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()