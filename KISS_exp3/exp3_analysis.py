#!/usr/bin/env python3
"""
EXP3 ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ ê²°ê³¼ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
python analyze_exp3_results.py --results_dir _/data/output --config exp3_training_fixed.json

ë””ë ‰í† ë¦¬ êµ¬ì¡°:
data/output/
â””â”€â”€ exp3_cell_optimization_training_fixed/
    â””â”€â”€ 2025_07_17/
        â””â”€â”€ 120233/
            â”œâ”€â”€ ecotf_s0_p43_0/  # ì‹œë“œë³„ í´ë”
            â”‚   â”œâ”€â”€ exp3_learning_progress_fixed.json
            â”‚   â””â”€â”€ exp3_trained_model_fixed.json
            â”œâ”€â”€ ecotf_s1_p43_0/
            â””â”€â”€ analysis_results/  # ë¶„ì„ ê²°ê³¼
"""

import json
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import argparse
import pandas as pd
from datetime import datetime
import scipy.stats as stats
import os
import sys
from collections import defaultdict
import re

# í•œê¸€ í°íŠ¸ ì„¤ì •
import platform
import matplotlib as mpl
if platform.system() == 'Linux':
    plt.rcParams['font.family'] = 'DejaVu Sans'
    plt.rcParams['axes.unicode_minus'] = False


class EXP3MultiSeedAnalyzer:
    def __init__(self, results_dir, config_file=None, output_dir=None):
        self.results_dir = Path(results_dir)
        self.config_file = config_file
        self.output_dir = Path(output_dir) if output_dir else self.results_dir / 'analysis_results'
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
        self.all_results = defaultdict(list)
        self.metrics = {}
        self.seed_data = {}  # ì‹œë“œë³„ ë°ì´í„° ì €ì¥
        
    def find_seed_directories(self):
        """ìƒˆë¡œìš´ ë””ë ‰í† ë¦¬ êµ¬ì¡°ì—ì„œ ì‹œë“œë³„ í´ë” ì°¾ê¸°"""
        seed_dirs = []
        
        print(f"ğŸ” ê²°ê³¼ ë””ë ‰í† ë¦¬ íƒìƒ‰: {self.results_dir}")
        
        if not self.results_dir.exists():
            print(f"âŒ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.results_dir}")
            return seed_dirs
        
        # ì‹œë“œ í´ë” íŒ¨í„´ (ì˜ˆ: ecotf_s0_p43_0, ecotf_s1_p43_0)
        seed_pattern = re.compile(r'.*_s(\d+)_p.*')
        
        # ì§ì ‘ í•˜ìœ„ ë””ë ‰í† ë¦¬ë“¤ í™•ì¸
        for item in self.results_dir.iterdir():
            if item.is_dir() and seed_pattern.match(item.name):
                # analysis_results í´ë”ëŠ” ì œì™¸
                if item.name != 'analysis_results':
                    seed_dirs.append(item)
        
        # ì‹œë“œ ë²ˆí˜¸ë¡œ ì •ë ¬
        seed_dirs.sort(key=lambda x: int(seed_pattern.match(x.name).group(1)))
        
        print(f"âœ… ë°œê²¬ëœ ì‹œë“œ í´ë”: {len(seed_dirs)}ê°œ")
        for seed_dir in seed_dirs[:5]:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
            print(f"   - {seed_dir.name}")
        if len(seed_dirs) > 5:
            print(f"   ... ê·¸ë¦¬ê³  {len(seed_dirs) - 5}ê°œ ë”")
        
        return seed_dirs
    
    def load_seed_results(self, seed_dir):
        """ì‹œë“œ ë””ë ‰í† ë¦¬ì—ì„œ ê²°ê³¼ íŒŒì¼ ë¡œë“œ"""
        progress_file = None
        model_file = None
        
        # í•´ë‹¹ ì‹œë“œ í´ë”ì—ì„œ íŒŒì¼ ì°¾ê¸°
        for file in seed_dir.iterdir():
            if 'learning_progress' in file.name and file.suffix == '.json':
                progress_file = file
            elif 'trained_model' in file.name and file.suffix == '.json':
                model_file = file
        
        if not progress_file or not model_file:
            print(f"âš ï¸ {seed_dir.name}ì—ì„œ í•„ìš”í•œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None, None
        
        # JSON íŒŒì¼ ë¡œë“œ
        try:
            with open(progress_file, 'r') as f:
                progress_data = json.load(f)
            with open(model_file, 'r') as f:
                model_data = json.load(f)
            return progress_data, model_data
        except Exception as e:
            print(f"âŒ {seed_dir.name} íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None, None
    
    def load_all_seeds(self):
        """ëª¨ë“  ì‹œë“œì˜ ë°ì´í„° ë¡œë“œ"""
        seed_dirs = self.find_seed_directories()
        
        if not seed_dirs:
            print("âŒ ë¶„ì„í•  ì‹œë“œ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        successful_loads = 0
        
        for seed_dir in seed_dirs:
            progress_data, model_data = self.load_seed_results(seed_dir)
            
            if progress_data and model_data:
                # ì‹œë“œ ë²ˆí˜¸ ì¶”ì¶œ
                seed_match = re.search(r'_s(\d+)_', seed_dir.name)
                seed_num = int(seed_match.group(1)) if seed_match else len(self.seed_data)
                
                self.seed_data[seed_num] = {
                    'progress': progress_data,
                    'model': model_data,
                    'dir': seed_dir
                }
                successful_loads += 1
        
        print(f"\nâœ… {successful_loads}/{len(seed_dirs)}ê°œ ì‹œë“œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
        return successful_loads > 0
    
    def calculate_seed_regret(self, progress_data, model_data):
        """í›„íšŒ(regret) ê³„ì‚°"""
        reward_history = progress_data.get('reward_history', [])
        arm_history = progress_data.get('arm_history', [])
        
        if not reward_history:
            return [], [], None, 0
        
        # ê° armì˜ í‰ê·  ë³´ìƒ ê³„ì‚°
        arm_rewards = defaultdict(list)
        for arm, reward in zip(arm_history, reward_history):
            arm_rewards[arm].append(reward)
        
        # ìµœì  arm ì°¾ê¸°
        arm_avg_rewards = {}
        for arm, rewards in arm_rewards.items():
            arm_avg_rewards[arm] = np.mean(rewards)
        
        if not arm_avg_rewards:
            return [], [], None, 0
            
        best_arm = max(arm_avg_rewards, key=arm_avg_rewards.get)
        best_reward = arm_avg_rewards[best_arm]
        
        # ëˆ„ì  í›„íšŒ ê³„ì‚°
        instant_regret = []
        for t, (chosen_arm, reward) in enumerate(zip(arm_history, reward_history)):
            regret = best_reward - reward
            instant_regret.append(max(0, regret))  # ìŒìˆ˜ í›„íšŒëŠ” 0ìœ¼ë¡œ
        
        cumulative_regret = np.cumsum(instant_regret).tolist()
        
        return cumulative_regret, instant_regret, best_arm, best_reward
    
    def calculate_energy_savings(self, progress_data):
        """ì—ë„ˆì§€ ì ˆê°ìœ¨ ê³„ì‚°"""
        baseline_power = progress_data.get('baseline_power', 0)
        power_history = progress_data.get('power_history', [])
        
        if not power_history or baseline_power == 0:
            return 0, baseline_power, 0
        
        avg_power = np.mean(power_history)
        savings = (baseline_power - avg_power) / baseline_power * 100
        
        return savings, baseline_power, avg_power
    
    def analyze_performance(self):
        """ì „ì²´ ì„±ëŠ¥ ë¶„ì„"""
        if not self.seed_data:
            print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\nğŸ“Š ì„±ëŠ¥ ë¶„ì„ ì¤‘...")
        
        # ê° ì‹œë“œë³„ ë¶„ì„
        for seed_num, data in sorted(self.seed_data.items()):
            progress_data = data['progress']
            model_data = data['model']
            
            # 1. í›„íšŒ ê³„ì‚°
            cumulative_regret, instant_regret, best_arm, best_reward = self.calculate_seed_regret(
                progress_data, model_data
            )
            self.all_results['cumulative_regret'].append(cumulative_regret)
            self.all_results['instant_regret'].append(instant_regret)
            self.all_results['best_reward'].append(best_reward)
            
            # 2. ì—ë„ˆì§€ ì ˆê°ìœ¨
            savings_rate, baseline_power, avg_power = self.calculate_energy_savings(progress_data)
            self.all_results['energy_savings'].append(savings_rate)
            self.all_results['baseline_power'].append(baseline_power)
            self.all_results['avg_power'].append(avg_power)
            
            # 3. ë³´ìƒ ì´ë ¥
            rewards = progress_data.get('reward_history', [])
            self.all_results['rewards'].append(rewards)
            
            # 4. ì²˜ë¦¬ëŸ‰ ì •ë³´
            throughput_history = progress_data.get('throughput_history', [])
            if throughput_history:
                avg_throughput = np.mean(throughput_history)
                self.all_results['avg_throughput'].append(avg_throughput)
            
            # 5. ìµœì¢… ê°€ì¤‘ì¹˜
            weights = model_data.get('weights', [])
            self.all_results['final_weights'].append(weights)
        
        # í†µê³„ ê³„ì‚°
        self.calculate_statistics()
    
    def calculate_statistics(self):
        """í†µê³„ ì§€í‘œ ê³„ì‚°"""
        # ì—ë„ˆì§€ ì ˆê°ìœ¨ í†µê³„
        if self.all_results['energy_savings']:
            self.metrics['energy_savings_mean'] = np.mean(self.all_results['energy_savings'])
            self.metrics['energy_savings_std'] = np.std(self.all_results['energy_savings'])
        else:
            self.metrics['energy_savings_mean'] = 0
            self.metrics['energy_savings_std'] = 0
        
        # í‰ê·  ë³´ìƒ
        if self.all_results['rewards']:
            all_rewards_flat = [r for rewards in self.all_results['rewards'] for r in rewards]
            self.metrics['reward_mean'] = np.mean(all_rewards_flat)
            self.metrics['reward_std'] = np.std(all_rewards_flat)
        
        # ì²˜ë¦¬ëŸ‰ í†µê³„
        if self.all_results['avg_throughput']:
            self.metrics['throughput_mean'] = np.mean(self.all_results['avg_throughput'])
            self.metrics['throughput_std'] = np.std(self.all_results['avg_throughput'])
        
        print(f"\nğŸ“ˆ ì£¼ìš” ì§€í‘œ:")
        print(f"  - í‰ê·  ì—ë„ˆì§€ ì ˆê°ìœ¨: {self.metrics['energy_savings_mean']:.1f}% Â± {self.metrics['energy_savings_std']:.1f}%")
        print(f"  - í‰ê·  ë³´ìƒ: {self.metrics.get('reward_mean', 0):.4f} Â± {self.metrics.get('reward_std', 0):.4f}")
        if 'throughput_mean' in self.metrics:
            print(f"  - í‰ê·  ì²˜ë¦¬ëŸ‰: {self.metrics['throughput_mean']:.2e} bits/s")
    
    def calculate_overall_regret(self):
        """ì „ì²´ í›„íšŒ ë¶„ì„"""
        if not self.all_results['cumulative_regret']:
            return
        
        # ëª¨ë“  ì‹œë“œì˜ ìµœëŒ€ ì—í”¼ì†Œë“œ ìˆ˜ ì°¾ê¸°
        max_episodes = max(len(regret) for regret in self.all_results['cumulative_regret'])
        
        # í‰ê·  ëˆ„ì  í›„íšŒ ê³„ì‚°
        aligned_regrets = []
        for regret in self.all_results['cumulative_regret']:
            # ì§§ì€ ì‹œë“œëŠ” ë§ˆì§€ë§‰ ê°’ìœ¼ë¡œ íŒ¨ë”©
            if len(regret) < max_episodes:
                padded = regret + [regret[-1]] * (max_episodes - len(regret))
            else:
                padded = regret[:max_episodes]
            aligned_regrets.append(padded)
        
        self.metrics['avg_cumulative_regret'] = np.mean(aligned_regrets, axis=0)
        self.metrics['std_cumulative_regret'] = np.std(aligned_regrets, axis=0)
        
        # í‰ê·  í›„íšŒ ê³„ì‚°
        self.metrics['avg_regret'] = self.metrics['avg_cumulative_regret'] / np.arange(1, max_episodes + 1)
    
    def plot_all_results(self, save_dir=None):
        """ëª¨ë“  ê²°ê³¼ ì‹œê°í™”"""
        save_dir = save_dir or self.output_dir
        
        print("\nğŸ“ˆ ê·¸ë˜í”„ ìƒì„± ì¤‘...")
        
        # 1. ëˆ„ì  ë³´ìƒ
        self.plot_cumulative_rewards(save_dir)
        
        # 2. ëˆ„ì  í›„íšŒ
        if 'avg_cumulative_regret' in self.metrics:
            self.plot_cumulative_regret(save_dir)
        
        # 3. í‰ê·  í›„íšŒ
        if 'avg_regret' in self.metrics:
            self.plot_average_regret(save_dir)
        
        # 4. Arm ì„ íƒ ë¶„í¬
        self.plot_selection_distribution(save_dir)
        
        # 5. ì—ë„ˆì§€-ì²˜ë¦¬ëŸ‰ ë¹„êµ
        self.plot_energy_throughput_comparison(save_dir)
        
        # 6. ìˆ˜ë ´ ë¶„ì„
        self.plot_convergence_analysis(save_dir)
        
        print(f"âœ… ëª¨ë“  ê·¸ë˜í”„ê°€ {save_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def plot_cumulative_rewards(self, save_dir):
        """ëˆ„ì  ë³´ìƒ ê·¸ë˜í”„"""
        plt.figure(figsize=(10, 6))
        
        # ê° ì‹œë“œë³„ ëˆ„ì  ë³´ìƒ
        for seed_num, rewards in enumerate(self.all_results['rewards']):
            if rewards:
                cumulative_rewards = np.cumsum(rewards)
                plt.plot(cumulative_rewards, alpha=0.3, label=f'Seed {seed_num}' if seed_num < 5 else None)
        
        # í‰ê·  ëˆ„ì  ë³´ìƒ
        if self.all_results['rewards']:
            max_len = max(len(r) for r in self.all_results['rewards'])
            aligned_rewards = []
            for rewards in self.all_results['rewards']:
                if len(rewards) < max_len:
                    padded = rewards + [rewards[-1]] * (max_len - len(rewards))
                else:
                    padded = rewards[:max_len]
                aligned_rewards.append(np.cumsum(padded))
            
            mean_cumulative = np.mean(aligned_rewards, axis=0)
            plt.plot(mean_cumulative, 'r-', linewidth=2, label='Average')
        
        plt.xlabel('Episode')
        plt.ylabel('Cumulative Reward')
        plt.title('Cumulative Rewards over Episodes')
        plt.legend(loc='best')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(save_dir / 'cumulative_rewards.png', dpi=300)
        plt.close()
    
    def plot_cumulative_regret(self, save_dir):
        """ëˆ„ì  í›„íšŒ ê·¸ë˜í”„"""
        plt.figure(figsize=(10, 6))
        
        episodes = np.arange(len(self.metrics['avg_cumulative_regret']))
        mean_regret = self.metrics['avg_cumulative_regret']
        std_regret = self.metrics['std_cumulative_regret']
        
        plt.plot(episodes, mean_regret, 'b-', linewidth=2, label='Mean')
        plt.fill_between(episodes, 
                        mean_regret - std_regret,
                        mean_regret + std_regret,
                        alpha=0.3, color='blue', label='Â±1 STD')
        
        plt.xlabel('Episode')
        plt.ylabel('Cumulative Regret')
        plt.title('Average Cumulative Regret over Episodes')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(save_dir / 'cumulative_regret.png', dpi=300)
        plt.close()
    
    def plot_average_regret(self, save_dir):
        """í‰ê·  í›„íšŒ ê·¸ë˜í”„"""
        plt.figure(figsize=(10, 6))
        
        episodes = np.arange(1, len(self.metrics['avg_regret']) + 1)
        avg_regret = self.metrics['avg_regret']
        
        plt.plot(episodes, avg_regret, 'g-', linewidth=2)
        plt.xlabel('Episode')
        plt.ylabel('Average Regret')
        plt.title('Average Regret per Episode')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(save_dir / 'average_regret.png', dpi=300)
        plt.close()
    
    def plot_selection_distribution(self, save_dir):
        """Arm ì„ íƒ ë¶„í¬"""
        plt.figure(figsize=(12, 6))
        
        # ëª¨ë“  ì‹œë“œì˜ ìµœì¢… ê°€ì¤‘ì¹˜ í‰ê· 
        if self.all_results['final_weights']:
            all_weights = np.array(self.all_results['final_weights'])
            mean_weights = np.mean(all_weights, axis=0)
            
            # ìƒìœ„ 10ê°œ arms
            top_indices = np.argsort(mean_weights)[-10:][::-1]
            
            plt.bar(range(len(top_indices)), mean_weights[top_indices])
            plt.xlabel('Top 10 Arms')
            plt.ylabel('Average Weight')
            plt.title('Distribution of Final Weights (Top 10 Arms)')
            plt.xticks(range(len(top_indices)), [f'Arm {i}' for i in top_indices], rotation=45)
            plt.grid(True, alpha=0.3, axis='y')
            plt.tight_layout()
            plt.savefig(save_dir / 'selection_distribution.png', dpi=300)
            plt.close()
    
    def plot_energy_throughput_comparison(self, save_dir):
        """ì—ë„ˆì§€-ì²˜ë¦¬ëŸ‰ ë¹„êµ"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
        
        # ì—ë„ˆì§€ ì ˆê°ìœ¨
        if self.all_results['energy_savings']:
            seeds = range(len(self.all_results['energy_savings']))
            ax1.bar(seeds, self.all_results['energy_savings'])
            ax1.axhline(y=self.metrics['energy_savings_mean'], color='r', linestyle='--',
                       label=f'Mean: {self.metrics["energy_savings_mean"]:.1f}%')
            ax1.set_xlabel('Seed')
            ax1.set_ylabel('Energy Savings (%)')
            ax1.set_title('Energy Savings by Seed')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
        
        # í‰ê·  ì²˜ë¦¬ëŸ‰
        if self.all_results['avg_throughput']:
            seeds = range(len(self.all_results['avg_throughput']))
            ax2.bar(seeds, self.all_results['avg_throughput'])
            if 'throughput_mean' in self.metrics:
                ax2.axhline(y=self.metrics['throughput_mean'], color='r', linestyle='--',
                           label=f'Mean: {self.metrics["throughput_mean"]:.2e}')
            ax2.set_xlabel('Seed')
            ax2.set_ylabel('Average Throughput (bits/s)')
            ax2.set_title('Average Throughput by Seed')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_dir / 'energy_throughput_comparison.png', dpi=300)
        plt.close()
    
    def plot_convergence_analysis(self, save_dir):
        """ìˆ˜ë ´ ë¶„ì„ ê·¸ë˜í”„"""
        if not self.all_results['final_weights']:
            return
            
        plt.figure(figsize=(10, 6))
        
        # ê° ì‹œë“œì˜ ê°€ì¤‘ì¹˜ ì—”íŠ¸ë¡œí”¼ ë³€í™”
        for seed_num, weights in enumerate(self.all_results['final_weights'][:10]):  # ì²˜ìŒ 10ê°œë§Œ
            weights_array = np.array(weights)
            # ì •ê·œí™”
            weights_norm = weights_array / weights_array.sum()
            # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
            entropy = -np.sum(weights_norm * np.log(weights_norm + 1e-10))
            plt.scatter(seed_num, entropy, label=f'Seed {seed_num}')
        
        plt.xlabel('Seed')
        plt.ylabel('Weight Entropy')
        plt.title('Weight Distribution Entropy by Seed')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(save_dir / 'convergence_analysis.png', dpi=300)
        plt.close()
    
    def save_summary(self):
        """ë¶„ì„ ìš”ì•½ ì €ì¥"""
        summary_file = self.output_dir / 'analysis_summary.txt'
        
        with open(summary_file, 'w') as f:
            f.write("EXP3 Multi-Seed Analysis Summary\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Results Directory: {self.results_dir}\n")
            f.write(f"Number of Seeds Analyzed: {len(self.seed_data)}\n\n")
            
            f.write("Key Performance Indicators:\n")
            f.write("-" * 30 + "\n")
            f.write(f"1. Energy Savings: {self.metrics['energy_savings_mean']:.1f}% Â± {self.metrics['energy_savings_std']:.1f}%\n")
            f.write(f"2. Average Reward: {self.metrics.get('reward_mean', 0):.4f} Â± {self.metrics.get('reward_std', 0):.4f}\n")
            if 'throughput_mean' in self.metrics:
                f.write(f"3. Average Throughput: {self.metrics['throughput_mean']:.2e} bits/s\n")
            if 'avg_regret' in self.metrics and len(self.metrics['avg_regret']) > 0:
                f.write(f"4. Final Average Regret: {self.metrics['avg_regret'][-1]:.4f}\n")
            
            f.write("\nSeed-wise Results:\n")
            f.write("-" * 30 + "\n")
            for seed_num in sorted(self.seed_data.keys())[:10]:  # ì²˜ìŒ 10ê°œë§Œ
                if seed_num < len(self.all_results['energy_savings']):
                    f.write(f"Seed {seed_num}: Energy Savings = {self.all_results['energy_savings'][seed_num]:.1f}%\n")
        
        # JSON í˜•ì‹ìœ¼ë¡œë„ ì €ì¥
        metrics_file = self.output_dir / 'analysis_metrics.json'
        save_metrics = {
            'summary': {
                'total_seeds': len(self.seed_data),
                'energy_savings_mean': self.metrics.get('energy_savings_mean', 0),
                'energy_savings_std': self.metrics.get('energy_savings_std', 0),
                'reward_mean': self.metrics.get('reward_mean', 0),
                'reward_std': self.metrics.get('reward_std', 0),
                'throughput_mean': self.metrics.get('throughput_mean', 0),
                'throughput_std': self.metrics.get('throughput_std', 0),
            },
            'timestamp': datetime.now().isoformat()
        }
        
        with open(metrics_file, 'w') as f:
            json.dump(save_metrics, f, indent=2)
        
        print(f"\nâœ… ë¶„ì„ ìš”ì•½ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
        print(f"   - {summary_file}")
        print(f"   - {metrics_file}")
    
    def run_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print("\nğŸš€ EXP3 ë‹¤ì¤‘ ì‹œë“œ ë¶„ì„ ì‹œì‘...")
        print("=" * 60)
        
        # 1. ëª¨ë“  ì‹œë“œ ë°ì´í„° ë¡œë“œ
        if not self.load_all_seeds():
            print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            return
        
        # 2. ì„±ëŠ¥ ë¶„ì„
        self.analyze_performance()
        
        # 3. í›„íšŒ ë¶„ì„
        self.calculate_overall_regret()
        
        # 4. ê²°ê³¼ ì‹œê°í™”
        self.plot_all_results()
        
        # 5. ìš”ì•½ ì €ì¥
        self.save_summary()
        
        print("\n" + "=" * 60)
        print("âœ… ë¶„ì„ ì™„ë£Œ!")


def run_analysis_integrated(config_file, output_base_dir="data/output", current_run_timestamp=None):
    """
    ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ë¶„ì„ í•¨ìˆ˜
    
    Args:
        config_file (str): ì‚¬ìš©ëœ ì„¤ì • íŒŒì¼ ê²½ë¡œ
        output_base_dir (str): ì¶œë ¥ ê¸°ë³¸ ë””ë ‰í† ë¦¬
        current_run_timestamp (str): í˜„ì¬ ì‹¤í–‰ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ (YYYY_MM_DD/HHMMSS í˜•ì‹)
    """
    print("\n" + "="*60)
    print("ğŸ”¬ EXP3 ì‹¤í—˜ ê²°ê³¼ ìë™ ë¶„ì„ ì‹œì‘...")
    print("="*60)
    
    # ì„¤ì • íŒŒì¼ì—ì„œ ì‹¤í—˜ ì´ë¦„ ì¶”ì¶œ
    with open(config_file, 'r') as f:
        config = json.load(f)
    
    experiment_name = config.get('experiment_description', 'exp3_experiment')
    
    # í˜„ì¬ ì‹¤í–‰ì˜ ê²°ê³¼ ë””ë ‰í† ë¦¬ ì§€ì •
    if current_run_timestamp:
        # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹±
        date_part, time_part = current_run_timestamp.split('/')
        results_dir = Path(output_base_dir) / experiment_name / date_part / time_part
    else:
        # ìµœì‹  ì‹¤í–‰ ì°¾ê¸°
        exp_dir = Path(output_base_dir) / experiment_name
        if not exp_dir.exists():
            print(f"âŒ ì‹¤í—˜ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {exp_dir}")
            return
        
        # ìµœì‹  ë‚ ì§œ/ì‹œê°„ ì°¾ê¸°
        latest_date = sorted([d for d in exp_dir.iterdir() if d.is_dir()], reverse=True)[0]
        latest_time = sorted([t for t in latest_date.iterdir() if t.is_dir()], reverse=True)[0]
        results_dir = latest_time
    
    print(f"ğŸ“ ë¶„ì„ ëŒ€ìƒ ë””ë ‰í† ë¦¬: {results_dir}")
    
    # ë¶„ì„ê¸° ì‹¤í–‰
    analyzer = EXP3MultiSeedAnalyzer(
        results_dir=results_dir,
        config_file=config_file
    )
    
    try:
        analyzer.run_analysis()
    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


def main():
    """ë…ë¦½ ì‹¤í–‰ìš© main í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="EXP3 ë‹¤ì¤‘ ì‹œë“œ ì‹¤í—˜ ê²°ê³¼ ë¶„ì„",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # íŠ¹ì • ì‹¤í–‰ ê²°ê³¼ ë¶„ì„
  python exp3_analysis.py --results_dir data/output/exp3_cell_optimization_training_fixed/2025_07_17/120233
  
  # ìµœì‹  ê²°ê³¼ ìë™ ì°¾ê¸°
  python exp3_analysis.py --experiment_name exp3_cell_optimization_training_fixed
        """
    )
    
    parser.add_argument(
        '--results_dir',
        type=str,
        help='ê²°ê³¼ê°€ ìˆëŠ” ì •í™•í•œ ë””ë ‰í† ë¦¬ ê²½ë¡œ'
    )
    
    parser.add_argument(
        '--experiment_name',
        type=str,
        help='ì‹¤í—˜ ì´ë¦„ (ìµœì‹  ê²°ê³¼ ìë™ ì°¾ê¸°)'
    )
    
    parser.add_argument(
        '--output_base_dir',
        type=str,
        default='data/output',
        help='ì¶œë ¥ ê¸°ë³¸ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: data/output)'
    )
    
    args = parser.parse_args()
    
    if args.results_dir:
        # ì§ì ‘ ì§€ì •ëœ ë””ë ‰í† ë¦¬ ë¶„ì„
        analyzer = EXP3MultiSeedAnalyzer(results_dir=args.results_dir)
        analyzer.run_analysis()
    elif args.experiment_name:
        # ìµœì‹  ê²°ê³¼ ì°¾ì•„ì„œ ë¶„ì„
        run_analysis_integrated(
            config_file=None,  # ë…ë¦½ ì‹¤í–‰ì‹œì—ëŠ” config íŒŒì¼ ì—†ì–´ë„ ë¨
            output_base_dir=args.output_base_dir,
            current_run_timestamp=None  # ìµœì‹  ì°¾ê¸°
        )
    else:
        parser.print_help()
        print("\nâŒ --results_dir ë˜ëŠ” --experiment_name ì¤‘ í•˜ë‚˜ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()