import argparse
from datetime import datetime
import json
import os
import subprocess
import time
import numpy as np
import signal
import multiprocessing as mp
from pathlib import Path
import sys
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# ë¶„ì„ ëª¨ë“ˆ import ì¶”ê°€
from exp3_analysis import EXP3MultiSeedAnalyzer

def send_email_notification(config_file, elapsed_time, timestamp):
    """
    ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ ì‹œ ì´ë©”ì¼ ì•Œë¦¼ì„ ë³´ë‚´ëŠ” í•¨ìˆ˜
    """
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì´ë©”ì¼ ì„¤ì • ì½ê¸°
    sender_email = os.environ.get('KISS_EMAIL_SENDER')
    sender_password = os.environ.get('KISS_EMAIL_PASSWORD')
    receiver_email = os.environ.get('KISS_EMAIL_RECEIVER')
    
    # í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš° ê²½ê³ 
    if not all([sender_email, sender_password, receiver_email]):
        print("âš ï¸  ì´ë©”ì¼ í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”:")
        print("  export KISS_EMAIL_SENDER='your_email@gmail.com'")
        print("  export KISS_EMAIL_PASSWORD='your_app_password'")
        print("  export KISS_EMAIL_RECEIVER='receiver_email@gmail.com'")
        return
    
    # ì´ë©”ì¼ ë‚´ìš© êµ¬ì„±
    subject = "KISS ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ"
    body = f"""
KISS ì‹œë®¬ë ˆì´ì…˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.

ì‹¤í–‰ ì •ë³´:
- ì„¤ì • íŒŒì¼: {config_file}
- ì‹¤í–‰ ì‹œê°„: {elapsed_time:.2f}ì´ˆ
- íƒ€ì„ìŠ¤íƒ¬í”„: {timestamp}
- ê²°ê³¼ ê²½ë¡œ: data/output/<experiment>/{timestamp.replace('/', '/')}/

ìë™ ìƒì„±ëœ ì•Œë¦¼ì…ë‹ˆë‹¤.
"""
    
    # ì´ë©”ì¼ ë©”ì‹œì§€ ìƒì„±
    message = MIMEMultipart()
    message["From"] = sender_email
    message["To"] = receiver_email
    message["Subject"] = subject
    message.attach(MIMEText(body, "plain"))
    
    try:
        # Gmail SMTP ì„œë²„ ì—°ê²°
        server = smtplib.SMTP("smtp.gmail.com", 587)
        server.starttls()
        server.login(sender_email, sender_password)
        
        # ì´ë©”ì¼ ì „ì†¡
        text = message.as_string()
        server.sendmail(sender_email, receiver_email, text)
        server.quit()
        
        print("âœ‰ï¸  ì´ë©”ì¼ ì•Œë¦¼ì´ ì„±ê³µì ìœ¼ë¡œ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âš ï¸  ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨: {e}")


def signal_handler(signum, frame):
    """
    Signal handler function that is called when a signal is received.

    Args:
        signum (int): The signal number.
        frame (frame): The current stack frame.

    Returns:
        None
    """
    print(f"Received signal {signum}, exiting...")
    remove_temp_json(json_file_list)
    exit(1)


def generate_config_dict_list(config_file, execution_timestamp=None):
    """
    Generate a list of dictionaries containing different configurations based on the input JSON file.

    Args:
        config_file (str): The path to the JSON file containing the configuration.
        execution_timestamp (str): The execution timestamp to use for all configs (YYYYMMDD_HHMMSS format)

    Returns:
        list: A list of dictionaries, where each dictionary represents a different configuration.
    """
    # Load the contents of the JSON file into a dictionary
    with open(config_file) as f:
        config = json.load(f)

    seed_max = config['seed']
    power_dBm = config['power_dBm']
    power_dBm_end = config['power_dBm_end']
    power_dBm_step = config['power_dBm_step']

    # Define the range of power values to test
    if power_dBm == power_dBm_end:
        power_values = [power_dBm]
    # If the finish power value is `-inf` then the range of power values will be from the start power value to `0dBm` in steps of `power_dBm_step`, and then an additional value of `-np.inf` will be added to the end of the list
    elif power_dBm_end == "-np.inf":
        power_values = np.arange(power_dBm, 0, -power_dBm_step)
        power_values = np.append(power_values, -np.inf)
    else:
        power_values = np.arange(power_dBm, power_dBm_end-power_dBm_step, -power_dBm_step)

    # Seed values to test 
    seeds = list(range(seed_max))

    # Define the number range of variable power cells
    n_variable_power_cells = list(range(1, config['n_variable_power_cells']+1))

    # Create a list of dictionaries
    config_dict_list = []
    for seed in seeds:
        for power_dBm in power_values:
            if len(n_variable_power_cells) == 0:
                # Create a new dictionary object for each iteration
                config_copy = config.copy()
                
                # Update the seed and power_dBm value in the new dictionary object
                config_copy['seed'] = seed
                config_copy['variable_cell_power_dBm'] = power_dBm
                config_copy['n_variable_power_cells'] = 0
                
                # Add execution timestamp if provided
                if execution_timestamp:
                    config_copy['execution_timestamp'] = execution_timestamp
                
                # Append the new dictionary object to the list
                config_dict_list.append(config_copy)
            else:
                # Create a new dictionary object for each iteration
                for n_cells in n_variable_power_cells:
                    config_copy = config.copy()
                    
                    # Update the values in the new dictionary object
                    config_copy['seed'] = seed
                    config_copy['variable_cell_power_dBm'] = power_dBm
                    config_copy['n_variable_power_cells'] = n_cells
                    
                    # Add execution timestamp if provided
                    if execution_timestamp:
                        config_copy['execution_timestamp'] = execution_timestamp
                    
                    # Append the new dictionary object to the list
                    config_dict_list.append(config_copy)

    return config_dict_list


def create_updated_json_file(config_dict, output_file):
    """
    Create an updated JSON file with the given configuration dictionary.

    Args:
        config_dict (dict): The configuration dictionary to write to the JSON file.
        output_file (str): The path to the output JSON file.

    Returns:
        None
    """
    # Write the updated dictionary to the output JSON file
    with open(output_file, 'w') as f:
        json.dump(config_dict, f, indent=4)


# Define a function that takes a list of dictionaries and dumps each dictionary to a separate JSON file
def dump_json(config_dict_list):
    # Create a list to store the JSON file paths
    json_file_list = []

    # Loop through each dictionary in the list
    for i, config_dict in enumerate(config_dict_list):
        # Create a unique JSON file name
        json_file_name = f"temp_{i}.json"

        # Dump the dictionary to the JSON file
        with open(json_file_name, 'w') as f:
            json.dump(config_dict, f, indent=4)

        # Append the JSON file path to the list
        json_file_list.append(json_file_name)

    # Return the list of JSON file paths
    return json_file_list


# Define a function that takes a single json file and runs kiss.py against it
def run_kiss(temp_json_file):
    # Define the command to execute
    command = ["python", "kiss.py", "-c", f"{temp_json_file}"]

    # Execute the command as a subprocess
    process = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

    # Print the output of the subprocess
    print(process.stdout.decode())
    if process.returncode != 0:
        print(process.stderr.decode())
        return process.returncode
    else:
        return process.returncode


# Define a function that takes a list of temp JSON file paths and removes them from the file system
def remove_temp_json(json_file_list):
    # Loop through each JSON file in the list
    for json_file in json_file_list:
        # Remove the JSON file from the file system
        try:
            os.remove(json_file)
            # test if file exists
            if os.path.exists(json_file):
                # tried removing and it still exists, so raise an error by moving to the except block below
                raise OSError
            else:
                # Get the json file name
                json_file_name = os.path.basename(json_file)
                print(f"File {json_file_name} removed successfully")
        except OSError as e:
            print(f"Error deleting file: {e}")


# Callback function to update progress
def update_progress(result):
    with progress_counter.get_lock():
        progress_counter.value += 1
        print(f"Processed {progress_counter.value} of {total_files} files")


# Global variables for signal handler
json_file_list = []
progress_counter = None
total_files = 0


def run_analysis(config_file, output_base_dir="data/output", current_run_timestamp=None):
    """
    ì‹¤í—˜ ì™„ë£Œ í›„ ìë™ ë¶„ì„ ì‹¤í–‰ - ìƒˆë¡œìš´ ë””ë ‰í† ë¦¬ êµ¬ì¡° ì§€ì›
    
    Args:
        config_file (str): ì‚¬ìš©ëœ ì„¤ì • íŒŒì¼ ê²½ë¡œ
        output_base_dir (str): ì¶œë ¥ ê¸°ë³¸ ë””ë ‰í† ë¦¬
        current_run_timestamp (str): í˜„ì¬ ì‹¤í–‰ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ (YYYY_MM_DD/HHMMSS í˜•ì‹)
    """
    print("\n" + "="*60)
    print("ğŸ”¬ EXP3 ì‹¤í—˜ ê²°ê³¼ ìë™ ë¶„ì„ ì‹œì‘...")
    print("="*60)
    
    # ì„¤ì • íŒŒì¼ì—ì„œ ì‹¤í—˜ ì´ë¦„ ì¶”ì¶œ
    with open(config_file, 'r') as f:
        config = json.load(f)
    
    experiment_name = config.get('experiment_description', 'exp3_experiment')
    
    # í˜„ì¬ ì‹¤í–‰ì˜ ê²°ê³¼ ë””ë ‰í† ë¦¬ ì§€ì •
    if current_run_timestamp:
        # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹± (YYYY_MM_DD/HHMMSS í˜•ì‹)
        date_part, time_part = current_run_timestamp.split('/')
        results_dir = Path(output_base_dir) / experiment_name / date_part / time_part
        
        print(f"ğŸ“ ë¶„ì„ ëŒ€ìƒ ë””ë ‰í† ë¦¬: {results_dir}")
        
        # ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸
        if not results_dir.exists():
            print(f"âš ï¸ ê²½ê³ : ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {results_dir}")
            
            # ëŒ€ì²´ ê²½ë¡œë“¤ ì‹œë„
            alt_paths = [
                Path(output_base_dir.replace("_/", "")) / experiment_name / date_part / time_part,
                Path("output") / experiment_name / date_part / time_part,
                Path(".") / "output" / experiment_name / date_part / time_part,
            ]
            
            for alt_path in alt_paths:
                if alt_path.exists():
                    print(f"âœ… ëŒ€ì²´ ê²½ë¡œì—ì„œ ë°œê²¬: {alt_path}")
                    results_dir = alt_path
                    break
            else:
                print("âŒ ê²°ê³¼ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("\nğŸ” í˜„ì¬ ë””ë ‰í† ë¦¬ êµ¬ì¡°:")
                try:
                    base = Path(output_base_dir) / experiment_name
                    if base.exists():
                        for date_dir in sorted(base.iterdir())[-3:]:  # ìµœê·¼ 3ê°œ ë‚ ì§œ
                            print(f"  {date_dir.name}/")
                            for time_dir in sorted(date_dir.iterdir())[-3:]:  # ìµœê·¼ 3ê°œ ì‹œê°„
                                print(f"    {time_dir.name}/")
                except:
                    pass
                return
    else:
        # ìµœì‹  ì‹¤í–‰ ì°¾ê¸°
        exp_dir = Path(output_base_dir) / experiment_name
        if not exp_dir.exists():
            print(f"âŒ ì‹¤í—˜ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {exp_dir}")
            return
        
        # ìµœì‹  ë‚ ì§œ ì°¾ê¸°
        dates = sorted([d for d in exp_dir.iterdir() if d.is_dir()], reverse=True)
        if not dates:
            print("âŒ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        latest_date = dates[0]
        
        # ìµœì‹  ì‹œê°„ ì°¾ê¸°
        times = sorted([t for t in latest_date.iterdir() if t.is_dir()], reverse=True)
        if not times:
            print("âŒ ì‹¤í–‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        latest_time = times[0]
        results_dir = latest_time
        
        print(f"ğŸ“ ìµœì‹  ê²°ê³¼ ë””ë ‰í† ë¦¬: {results_dir}")
    
    
    # ë¶„ì„ê¸° ì‹¤í–‰
    analyzer = EXP3MultiSeedAnalyzer(
        results_dir=results_dir,
        config_file=config_file
    )
    
    try:
        # ìƒˆë¡œìš´ ë©”ì„œë“œ ì´ë¦„ ì‚¬ìš©
        analyzer.run_analysis()
        
        print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ëŠ” ë‹¤ìŒ ìœ„ì¹˜ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
        print(f"   {analyzer.output_dir}")
        
        # ì£¼ìš” ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        summary_file = analyzer.output_dir / 'analysis_summary.txt'
        if summary_file.exists():
            print("\nğŸ“‹ ë¶„ì„ ìš”ì•½:")
            print("-" * 40)
            # ìš”ì•½ì˜ ì¼ë¶€ë§Œ ì¶œë ¥ (ì²˜ìŒ 10ì¤„)
            with open(summary_file, 'r') as f:
                lines = f.readlines()
                for line in lines[:15]:  # ì²˜ìŒ 15ì¤„ë§Œ
                    print(line.rstrip())
                if len(lines) > 15:
                    print("... (ìì„¸í•œ ë‚´ìš©ì€ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”)")
                
    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        
        # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥
        print("\nğŸ” ë””ë²„ê¹… ì •ë³´:")
        print(f"  - ê²°ê³¼ ë””ë ‰í† ë¦¬: {results_dir}")
        print(f"  - ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€: {results_dir.exists()}")
        if results_dir.exists():
            print(f"  - í•˜ìœ„ í´ë” ìˆ˜: {len(list(results_dir.iterdir()))}")
            # ì²˜ìŒ 5ê°œ í•˜ìœ„ í´ë” ì¶œë ¥
            for i, item in enumerate(results_dir.iterdir()):
                if i >= 5:
                    print("    ...")
                    break
                print(f"    - {item.name}")



if __name__ == '__main__':
    # Register the signal handler function to handle the SIGINT and SIGTERM signals
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # Parse the command line arguments
    parser = argparse.ArgumentParser(
        description='Run kiss.py against a specified config value.')
    parser.add_argument(
        '-c',
        '--config-file',
        type=str,
        required=True,
        default='_test/data/input/kiss/test_kiss.json'
    )
    parser.add_argument(
        '--no-analysis',
        action='store_true',
        help='ë¶„ì„ì„ ê±´ë„ˆë›°ê³  ì‹œë®¬ë ˆì´ì…˜ë§Œ ì‹¤í–‰'
    )
    parser.add_argument(
        '--analysis-only',
        action='store_true',
        help='ì‹œë®¬ë ˆì´ì…˜ì„ ê±´ë„ˆë›°ê³  ê¸°ì¡´ ê²°ê³¼ë§Œ ë¶„ì„'
    )
    parser.add_argument(
        '--analysis-date',
        type=str,
        help='ë¶„ì„í•  ì‹¤í–‰ ë‚ ì§œ (YYYY_MM_DD í˜•ì‹, --analysis-onlyì™€ í•¨ê»˜ ì‚¬ìš©)'
    )
    
    # ì´ë©”ì¼ ì•Œë¦¼ ì˜µì…˜ ì¶”ê°€
    parser.add_argument(
        '--email-notification',
        action='store_true',
        help='ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ ì‹œ ì´ë©”ì¼ ì•Œë¦¼ ì „ì†¡'
    )
    
    args = parser.parse_args()

    # ë¶„ì„ë§Œ ìˆ˜í–‰í•˜ëŠ” ê²½ìš°
    if args.analysis_only:
        if args.analysis_date:
            # ë‚ ì§œê°€ ì§€ì •ëœ ê²½ìš° ì •í™•í•œ í˜•ì‹ìœ¼ë¡œ ì „ë‹¬
            run_analysis(args.config_file, current_run_timestamp=args.analysis_date)
        else:
            # ë‚ ì§œê°€ ì—†ìœ¼ë©´ ìµœì‹  ê²°ê³¼ ë¶„ì„
            run_analysis(args.config_file)
        exit(0)

    # Start the timer
    start_time = time.time()
    
    # í˜„ì¬ ì‹¤í–‰ì˜ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„± (ëª¨ë“  ì‹œë“œê°€ ê³µìœ )
    current_run_date_raw = datetime.now().strftime("%Y%m%d")  # "20250721"
    current_run_date = datetime.now().strftime("%Y_%m_%d")    # "2025_07_21" (ë””ë ‰í† ë¦¬ìš©)
    current_run_time = datetime.now().strftime("%H%M%S")      # "015124"
    execution_timestamp = f"{current_run_date_raw}_{current_run_time}"  # "20250721_015124"

    print(f"ğŸš€ Starting execution with timestamp: {execution_timestamp}")
    print(f"ğŸ“ Results will be saved in: data/output/<experiment>/{current_run_date}/{current_run_time}/")
    
    config_dict_list = generate_config_dict_list(args.config_file, execution_timestamp=execution_timestamp)

    # Dump the list of dictionaries to individual JSON files
    json_file_list = dump_json(config_dict_list)
    total_files = len(json_file_list)

    # Initialize a multiprocessing pool with more processes for your 14-core CPU
    # Using 12 processes to leave some CPU headroom for the system
    num_processes = 12
    num_tasks_per_child = 1
    progress_counter = mp.Value('i', 0)  # Shared variable to keep track of progress

    print(f"Starting parallel processing with {num_processes} processes for {total_files} simulations...")
    print(f"Results will be saved in: data/output/<experiment>/{current_run_date}/{current_run_time}/")

    with mp.Pool(processes=num_processes, maxtasksperchild=num_tasks_per_child) as pool:
        # Store async results
        async_results = []
        
        # Submit all tasks asynchronously
        for json_file in json_file_list:
            # Apply async with callback for progress tracking
            result = pool.apply_async(run_kiss, args=(json_file,), callback=update_progress)
            async_results.append(result)
        
        # Close the pool to prevent any more tasks from being submitted
        pool.close()
        
        # Wait for all processes to complete
        pool.join()
        
        # Optionally, check for any errors in the results
        for i, result in enumerate(async_results):
            try:
                return_code = result.get(timeout=1)  # Should already be done
                if return_code != 0:
                    print(f"Warning: Task {i+1} returned non-zero exit code: {return_code}")
            except Exception as e:
                print(f"Error in task {i+1}: {e}")

    # Remove the temporary JSON files
    remove_temp_json(json_file_list)

    # Stop the timer
    end_time = time.time()

    # Calculate the elapsed time
    elapsed_time = end_time - start_time

    # Print the elapsed time
    print(f"All subprocesses completed in {elapsed_time:.2f} seconds")
    print(f"Average time per simulation: {elapsed_time/total_files:.2f} seconds")
    
    # ìë™ ë¶„ì„ ì‹¤í–‰ (--no-analysis ì˜µì…˜ì´ ì—†ëŠ” ê²½ìš°)
    if not args.no_analysis:
        # ì ì‹œ ëŒ€ê¸° (íŒŒì¼ ì‹œìŠ¤í…œ ë™ê¸°í™”)
        print("\nâ³ íŒŒì¼ ì‹œìŠ¤í…œ ë™ê¸°í™” ëŒ€ê¸° ì¤‘...")
        time.sleep(2)
        
        # ë¶„ì„ ì‹¤í–‰ - ì „ì²´ íƒ€ì„ìŠ¤íƒ¬í”„ ì „ë‹¬
        timestamp = f"{current_run_date}/{current_run_time}"
        print(f"\nğŸ” ë¶„ì„ ì‹œì‘: {timestamp}")
        run_analysis(args.config_file, current_run_timestamp=timestamp)
    else:
        print("\nğŸ’¡ ë¶„ì„ì„ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë¶„ì„í•˜ë ¤ë©´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
        print(f"   python run_kiss.py -c {args.config_file} --analysis-only --analysis-date {current_run_date}/{current_run_time}")
        

    timestamp = f"{current_run_date}/{current_run_time}"
    send_email_notification(args.config_file, elapsed_time, timestamp)