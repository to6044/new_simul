#!/usr/bin/env python3
"""
EXP3 ìˆ˜ì •ì‚¬í•­ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
python test_exp3_fixes.py --config exp3_training_fixed.json

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìˆ˜ì •ëœ EXP3 êµ¬í˜„ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
"""

import json
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import argparse
import sys
import matplotlib as mpl

# í•œê¸€ í°íŠ¸ ì„¤ì •
import platform
if platform.system() == 'Linux':
    # Linuxì—ì„œ í•œê¸€ í°íŠ¸ ì„¤ì •
    try:
        import matplotlib.font_manager as fm
        # ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ê²½ë¡œ ì°¾ê¸°
        font_paths = [
            '/usr/share/fonts/truetype/nanum/NanumGothic.ttf',
            '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf',
            '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'
        ]
        
        font_found = False
        for font_path in font_paths:
            if Path(font_path).exists():
                font_prop = fm.FontProperties(fname=font_path)
                plt.rcParams['font.family'] = font_prop.get_name()
                plt.rcParams['axes.unicode_minus'] = False
                font_found = True
                break
        
        if not font_found:
            # í°íŠ¸ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
            plt.rcParams['font.family'] = 'DejaVu Sans'
            plt.rcParams['axes.unicode_minus'] = False
            
    except Exception as e:
        print(f"í°íŠ¸ ì„¤ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì˜ì–´ë¡œë§Œ í‘œì‹œ
        mpl.rcParams['axes.unicode_minus'] = False

def load_exp3_results(results_dir):
    """EXP3 ê²°ê³¼ íŒŒì¼ë“¤ì„ ë¡œë“œ"""
    results_dir = Path(results_dir)
    
    print(f"ğŸ” ê²°ê³¼ ë””ë ‰í† ë¦¬ íƒìƒ‰ ì¤‘: {results_dir.absolute()}")
    
    # í˜„ì¬ ë””ë ‰í† ë¦¬ë¶€í„° ì‹œì‘í•´ì„œ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰
    search_patterns = [
        "**/exp3_learning_progress*.json",
        "**/exp3_trained_model*.json", 
        "exp3_learning_progress*.json",
        "exp3_trained_model*.json"
    ]
    
    progress_files = []
    model_files = []
    
    # ì—¬ëŸ¬ íŒ¨í„´ìœ¼ë¡œ íŒŒì¼ íƒìƒ‰
    for pattern in search_patterns[:2]:  # progress íŒŒì¼ ì°¾ê¸°
        files = list(results_dir.glob(pattern))
        progress_files.extend([f for f in files if 'progress' in f.name])
    
    for pattern in search_patterns[:2]:  # model íŒŒì¼ ì°¾ê¸°  
        files = list(results_dir.glob(pattern))
        model_files.extend([f for f in files if 'model' in f.name and 'progress' not in f.name])
    
    # ì¤‘ë³µ ì œê±°
    progress_files = list(set(progress_files))
    model_files = list(set(model_files))
    
    print(f"ğŸ” ë°œê²¬ëœ progress íŒŒì¼: {len(progress_files)}ê°œ")
    for f in progress_files:
        print(f"   - {f}")
        
    print(f"ğŸ” ë°œê²¬ëœ model íŒŒì¼: {len(model_files)}ê°œ")
    for f in model_files:
        print(f"   - {f}")
    
    if not progress_files:
        print("\nâŒ í•™ìŠµ ì§„í–‰ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ íŒíŠ¸: ë‹¤ìŒ ìœ„ì¹˜ì—ì„œ íŒŒì¼ì„ í™•ì¸í•´ë³´ì„¸ìš”:")
        print("   - _/data/output/**/exp3_learning_progress*.json")
        print("   - data/output/**/exp3_learning_progress*.json")
        return None, None
        
    if not model_files:
        print("\nâŒ í›ˆë ¨ëœ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None
    
    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì„ íƒ
    progress_file = sorted(progress_files, key=lambda x: x.stat().st_mtime)[-1]
    model_file = sorted(model_files, key=lambda x: x.stat().st_mtime)[-1]
    
    print(f"\nğŸ“Š ì‚¬ìš©í•  Progress file: {progress_file}")
    print(f"ğŸ¤– ì‚¬ìš©í•  Model file: {model_file}")
    
    # íŒŒì¼ ë¡œë“œ
    with open(progress_file, 'r') as f:
        progress_data = json.load(f)
    
    with open(model_file, 'r') as f:
        model_data = json.load(f)
    
    return progress_data, model_data

def analyze_power_measurements(progress_data):
    """ì „ë ¥ ì¸¡ì • ì •í™•ì„± ë¶„ì„"""
    print("\nğŸ”‹ ì „ë ¥ ì¸¡ì • ë¶„ì„:")
    
    baseline_power = progress_data.get('baseline_power', 0)
    print(f"  ë² ì´ìŠ¤ë¼ì¸ ì „ë ¥: {baseline_power:.2f} kW")
    
    # ë” í˜„ì‹¤ì ì¸ ë²”ìœ„ë¡œ ìˆ˜ì • (19ê°œ ì…€ * 2-4kW)
    expected_min = 19 * 2.0  # 38 kW
    expected_max = 19 * 4.0  # 76 kW
    
    if expected_min <= baseline_power <= expected_max:
        print(f"  âœ… ë² ì´ìŠ¤ë¼ì¸ ì „ë ¥ì´ ì˜ˆìƒ ë²”ìœ„({expected_min:.1f}-{expected_max:.1f} kW) ë‚´ì— ìˆìŠµë‹ˆë‹¤.")
    else:
        print(f"  âš ï¸ ë² ì´ìŠ¤ë¼ì¸ ì „ë ¥ì´ ì˜ˆìƒ ë²”ìœ„({expected_min:.1f}-{expected_max:.1f} kW)ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.")

def analyze_reward_distribution(progress_data):
    """ë³´ìƒ ë¶„í¬ ë¶„ì„"""
    print("\nğŸ¯ ë³´ìƒ ë¶„í¬ ë¶„ì„:")
    
    reward_history = progress_data.get('reward_history', [])
    
    if reward_history:
        rewards = np.array(reward_history)
        print(f"  ì´ ì—í”¼ì†Œë“œ: {len(rewards)}")
        print(f"  ë³´ìƒ ë²”ìœ„: [{rewards.min():.4f}, {rewards.max():.4f}]")
        print(f"  í‰ê·  ë³´ìƒ: {rewards.mean():.4f}")
        print(f"  ë³´ìƒ í‘œì¤€í¸ì°¨: {rewards.std():.4f}")
        
        # í¬í™”ë„ í™•ì¸
        saturation_count = np.sum(rewards >= 0.99)
        saturation_rate = saturation_count / len(rewards) * 100
        
        if saturation_rate < 5:
            print(f"  âœ… ë³´ìƒ ë¶„í¬ ì–‘í˜¸: í¬í™”ìœ¨ {saturation_rate:.1f}%")
        else:
            print(f"  âš ï¸ ë³´ìƒ í¬í™” ë°œìƒ: {saturation_rate:.1f}%ê°€ 0.99 ì´ìƒ")

def analyze_learning_convergence(model_data):
    """í•™ìŠµ ìˆ˜ë ´ì„± ë¶„ì„"""
    print("\nğŸ“ˆ í•™ìŠµ ìˆ˜ë ´ ë¶„ì„:")
    
    weights = np.array(model_data.get('weights', []))
    episode = model_data.get('total_episodes', 0)
    
    print(f"  ì´ í•™ìŠµ ì—í”¼ì†Œë“œ: {episode}")
    print(f"  ê°€ì¤‘ì¹˜ ë²”ìœ„: [{weights.min():.4f}, {weights.max():.4f}]")
    
    # ê°€ì¤‘ì¹˜ ë¹„ìœ¨ ê³„ì‚°
    weight_ratio = weights.max() / max(weights.min(), 1e-10)
    print(f"  ê°€ì¤‘ì¹˜ ë¹„ìœ¨: {weight_ratio:.2f}")
    
    # ìƒìœ„ 5ê°œ arms ì¶œë ¥
    top_indices = np.argsort(weights)[-5:][::-1]
    print("  ìƒìœ„ 5 arms:")
    for rank, idx in enumerate(top_indices):
        cells = model_data['arms'][idx]
        print(f"    {rank+1}. Arm {idx}: cells {cells}, weight={weights[idx]:.4f}")
    
    # ìˆ˜ë ´ íŒë‹¨ ê¸°ì¤€ ì™„í™”
    if weight_ratio >= 1.05:  # ê¸°ì¡´ 3ì—ì„œ 1.05ë¡œ ë‚®ì¶¤
        print("  âœ… í•™ìŠµì´ ìˆ˜ë ´í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("  âŒ ìˆ˜ë ´í•˜ì§€ ì•ŠìŒ. ë” ê¸´ í•™ìŠµì´ë‚˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • í•„ìš”.")

def analyze_efficiency_improvements(progress_data, model_data):
    """íš¨ìœ¨ì„± ê°œì„  ë¶„ì„"""
    print("\nâš¡ íš¨ìœ¨ì„± ê°œì„  ë¶„ì„:")
    
    baseline_eff = progress_data.get('baseline_efficiency', 0)
    efficiency_history = progress_data.get('efficiency_history', [])
    
    if baseline_eff and efficiency_history:
        effs = np.array(efficiency_history)
        print(f"  ë² ì´ìŠ¤ë¼ì¸ íš¨ìœ¨ì„±: {baseline_eff:.2e} bits/J")
        print(f"  ê´€ì°°ëœ íš¨ìœ¨ì„± ë²”ìœ„: [{effs.min():.2e}, {effs.max():.2e}] bits/J")
        
        # ê°œì„ ìœ¨ ê³„ì‚°
        max_improvement = (effs.max() - baseline_eff) / baseline_eff * 100
        max_degradation = (effs.min() - baseline_eff) / baseline_eff * 100
        
        print(f"  ìµœëŒ€ ê°œì„ ìœ¨: {max_improvement:+.1f}%")
        print(f"  ìµœëŒ€ ì €í•˜ìœ¨: {max_degradation:+.1f}%")
        
        # í‰ê°€
        if max_improvement > 5:
            print("  âœ… ìœ ì˜ë¯¸í•œ íš¨ìœ¨ì„± ê°œì„  ë‹¬ì„±!")
        elif max_improvement > 0:
            print("  âš ï¸ ì†Œí­ ê°œì„ . ë” ê¸´ í•™ìŠµ ë˜ëŠ” íŒŒë¼ë¯¸í„° ì¡°ì • ê³ ë ¤.")
        else:
            print("  âŒ íš¨ìœ¨ì„± ê°œì„  ì—†ìŒ. ì•Œê³ ë¦¬ì¦˜ ê²€í†  í•„ìš”.")

def generate_diagnostic_plots(progress_data, save_dir=None):
    """ì§„ë‹¨ í”Œë¡¯ ìƒì„± (ì˜ì–´ ë²„ì „)"""
    print("\nğŸ“Š ì§„ë‹¨ í”Œë¡¯ ìƒì„± ì¤‘...")
    
    reward_history = progress_data.get('reward_history', [])
    efficiency_history = progress_data.get('efficiency_history', [])
    
    if not reward_history and not efficiency_history:
        print("  âŒ í”Œë¡¯ ìƒì„±í•  ë°ì´í„° ì—†ìŒ")
        return
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    fig.suptitle('EXP3 Learning Diagnostics', fontsize=16)
    
    # ë³´ìƒ íˆìŠ¤í† ë¦¬
    if reward_history:
        ax = axes[0, 0]
        ax.plot(reward_history)
        ax.set_title('Reward History')
        ax.set_xlabel('Episode')
        ax.set_ylabel('Reward')
        ax.grid(True, alpha=0.3)
    
    # ë³´ìƒ íˆìŠ¤í† ê·¸ë¨
    if reward_history:
        ax = axes[0, 1]
        ax.hist(reward_history, bins=20, alpha=0.7, edgecolor='black')
        ax.set_title('Reward Distribution')
        ax.set_xlabel('Reward Value')
        ax.set_ylabel('Frequency')
        ax.grid(True, alpha=0.3)
    
    # íš¨ìœ¨ì„± íˆìŠ¤í† ë¦¬
    if efficiency_history:
        ax = axes[1, 0]
        ax.plot(efficiency_history)
        ax.set_title('Network Efficiency')
        ax.set_xlabel('Episode')
        ax.set_ylabel('Efficiency (bits/J)')
        ax.grid(True, alpha=0.3)
        
        # ë² ì´ìŠ¤ë¼ì¸ í‘œì‹œ
        baseline = progress_data.get('baseline_efficiency')
        if baseline:
            ax.axhline(y=baseline, color='r', linestyle='--', label='Baseline')
            ax.legend()
    
    # ì´ë™í‰ê·  ë³´ìƒ
    if reward_history and len(reward_history) > 20:
        ax = axes[1, 1]
        window = min(20, len(reward_history) // 5)
        moving_avg = np.convolve(reward_history, np.ones(window)/window, mode='valid')
        ax.plot(range(window-1, len(reward_history)), moving_avg, 'r-', linewidth=2)
        ax.set_title(f'Reward Moving Average (window={window})')
        ax.set_xlabel('Episode')
        ax.set_ylabel('Average Reward')
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    if save_dir:
        save_path = Path(save_dir) / 'exp3_diagnostic_plots.png'
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"  ğŸ“ˆ í”Œë¡¯ ì €ì¥ë¨: {save_path}")
    else:
        plt.show()
    
    plt.close()

def analyze_regret_from_data(progress_data, model_data):
    """
    ì €ì¥ëœ ë°ì´í„°ë¡œë¶€í„° regret ê³„ì‚° ë° ë¶„ì„
    
    Parameters:
    -----------
    progress_data : dict
        í•™ìŠµ ì§„í–‰ ë°ì´í„°
    model_data : dict
        ìµœì¢… ëª¨ë¸ ë°ì´í„°
    """
    print("\nğŸ“Š Regret ë¶„ì„ (ì‚¬í›„ ê³„ì‚°):")
    
    # í•„ìš”í•œ ë°ì´í„° ì¶”ì¶œ
    reward_history = progress_data.get('reward_history', [])
    arm_selection_count = np.array(progress_data.get('arm_selection_count', []))
    cumulative_rewards = np.array(progress_data.get('cumulative_rewards', []))
    selected_arm_history = progress_data.get('selected_arm_history', [])
    
    if not reward_history or len(arm_selection_count) == 0:
        print("  âŒ Regret ê³„ì‚°ì— í•„ìš”í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê° armì˜ í‰ê·  ë³´ìƒ ê³„ì‚°
    avg_rewards = np.zeros(len(arm_selection_count))
    for i in range(len(arm_selection_count)):
        if arm_selection_count[i] > 0:
            avg_rewards[i] = cumulative_rewards[i] / arm_selection_count[i]
    
    # ìµœì  arm ì°¾ê¸°
    best_arm_idx = np.argmax(avg_rewards)
    best_arm_avg_reward = avg_rewards[best_arm_idx]
    
    print(f"  ìµœì  arm: {best_arm_idx} (í‰ê·  ë³´ìƒ: {best_arm_avg_reward:.4f})")
    
    # Cumulative regret ê³„ì‚°
    cumulative_regret = 0
    cumulative_regret_history = []
    instant_regret_history = []
    
    for t, (selected_arm, reward) in enumerate(zip(selected_arm_history, reward_history)):
        # ìˆœê°„ regret = ìµœì  armì˜ í‰ê·  ë³´ìƒ - ì‹¤ì œ ë°›ì€ ë³´ìƒ
        instant_regret = best_arm_avg_reward - reward
        instant_regret_history.append(instant_regret)
        
        cumulative_regret += instant_regret
        cumulative_regret_history.append(cumulative_regret)
    
    # í†µê³„ ê³„ì‚°
    T = len(reward_history)
    K = len(arm_selection_count)
    
    # EXP3ì˜ ì´ë¡ ì  regret bound: O(âˆš(TK log K))
    theoretical_bound = 2 * np.sqrt(T * K * np.log(K))
    
    # ì‹¤ì œ í‰ê·  ë³´ìƒ
    actual_avg_reward = np.mean(reward_history)
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"  ì´ ì—í”¼ì†Œë“œ: {T}")
    print(f"  ì´ arm ìˆ˜: {K}")
    print(f"  ëˆ„ì  regret: {cumulative_regret:.4f}")
    print(f"  í‰ê·  regret: {cumulative_regret / T:.4f}")
    print(f"  ì´ë¡ ì  ìƒí•œ: {theoretical_bound:.4f}")
    print(f"  Regret ë¹„ìœ¨: {cumulative_regret / theoretical_bound:.2%}")
    print(f"  ì‹¤ì œ í‰ê·  ë³´ìƒ: {actual_avg_reward:.4f}")
    print(f"  ìµœì  ëŒ€ë¹„ ì„±ëŠ¥: {actual_avg_reward / best_arm_avg_reward:.2%}")
    
    # í‰ê°€
    if cumulative_regret / theoretical_bound < 0.5:
        print("  âœ… ìš°ìˆ˜í•œ regret ì„±ëŠ¥ (ì´ë¡ ì  ìƒí•œì˜ 50% ë¯¸ë§Œ)")
    elif cumulative_regret / theoretical_bound < 1.0:
        print("  âš ï¸ ì–‘í˜¸í•œ regret ì„±ëŠ¥ (ì´ë¡ ì  ìƒí•œ ì´ë‚´)")
    else:
        print("  âŒ regretì´ ì´ë¡ ì  ìƒí•œì„ ì´ˆê³¼. ì•Œê³ ë¦¬ì¦˜ ì¡°ì • í•„ìš”")
    
    # Regret í”Œë¡¯ ìƒì„±
    plot_regret_analysis(cumulative_regret_history, instant_regret_history, 
                        theoretical_bound, K, save_path='regret_analysis.png')

def plot_regret_analysis(cumulative_regret_history, instant_regret_history, 
                         theoretical_bound, n_arms, save_path=None):
    """Regret ë¶„ì„ í”Œë¡¯ ìƒì„±"""
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    fig.suptitle('EXP3 Regret Analysis', fontsize=16)
    
    episodes = range(1, len(cumulative_regret_history) + 1)
    
    # ëˆ„ì  regret
    ax = axes[0, 0]
    ax.plot(episodes, cumulative_regret_history, 'b-', label='Actual', linewidth=2)
    
    # ì´ë¡ ì  bound
    theoretical_bounds = [2 * np.sqrt(t * n_arms * np.log(n_arms)) for t in episodes]
    ax.plot(episodes, theoretical_bounds, 'r--', label='Theoretical Bound', linewidth=2)
    ax.set_xlabel('Episode')
    ax.set_ylabel('Cumulative Regret')
    ax.set_title('Cumulative Regret vs Theoretical Bound')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # ìˆœê°„ regret
    ax = axes[0, 1]
    ax.plot(instant_regret_history, alpha=0.7)
    ax.set_xlabel('Episode')
    ax.set_ylabel('Instant Regret')
    ax.set_title('Instant Regret per Episode')
    ax.grid(True, alpha=0.3)
    
    # í‰ê·  regret
    ax = axes[1, 0]
    avg_regret = [cumulative_regret_history[i] / (i + 1) 
                 for i in range(len(cumulative_regret_history))]
    ax.plot(avg_regret, 'g-', linewidth=2)
    ax.set_xlabel('Episode')
    ax.set_ylabel('Average Regret')
    ax.set_title('Average Regret over Time')
    ax.grid(True, alpha=0.3)
    
    # Regret ë¹„ìœ¨
    ax = axes[1, 1]
    regret_ratios = [cumulative_regret_history[i] / theoretical_bounds[i] 
                    if theoretical_bounds[i] > 0 else 0 
                    for i in range(len(cumulative_regret_history))]
    ax.plot(regret_ratios, 'm-', linewidth=2)
    ax.axhline(y=1.0, color='r', linestyle='--', alpha=0.5, label='Theoretical Limit')
    ax.set_xlabel('Episode')
    ax.set_ylabel('Regret Ratio')
    ax.set_title('Actual / Theoretical Regret')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"\n  ğŸ“ˆ Regret ë¶„ì„ í”Œë¡¯ ì €ì¥: {save_path}")
    else:
        plt.show()
    
    plt.close()



def main():
    parser = argparse.ArgumentParser(
        description='EXP3 ìˆ˜ì •ì‚¬í•­ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python test_exp3_fixes.py                                    # ê¸°ë³¸ ë””ë ‰í† ë¦¬ì—ì„œ ê²€ìƒ‰
  python test_exp3_fixes.py --results_dir _/data/output        # íŠ¹ì • ë””ë ‰í† ë¦¬ ì§€ì •
  python test_exp3_fixes.py --results_dir . --save_plots       # í˜„ì¬ ë””ë ‰í† ë¦¬ì—ì„œ ê²€ìƒ‰í•˜ê³  í”Œë¡¯ ì €ì¥
  
ì£¼ì˜ì‚¬í•­:
  - ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ í›„ì— ì‚¬ìš©í•˜ì„¸ìš”
  - exp3_learning_progress*.jsonê³¼ exp3_trained_model*.json íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤
  - ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰: python run_kiss.py -c data/input/exp3_cell_on_off/exp3_training_fixed.json
        """
    )
    parser.add_argument(
        '--results_dir', 
        type=str, 
        default='.',
        help='ê²°ê³¼ íŒŒì¼ì„ ê²€ìƒ‰í•  ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: í˜„ì¬ ë””ë ‰í† ë¦¬)'
    )
    parser.add_argument(
        '--save_plots', 
        action='store_true',
        help='í”Œë¡¯ì„ íŒŒì¼ë¡œ ì €ì¥ (ê¸°ë³¸ê°’: í™”ë©´ì— í‘œì‹œ)'
    )
    
    args = parser.parse_args()
    
    print("ğŸ” EXP3 ìˆ˜ì •ì‚¬í•­ ê²€ì¦ ì‹œì‘...")
    print("=" * 60)
    
    # ê²°ê³¼ ë¡œë“œ
    progress_data, model_data = load_exp3_results(args.results_dir)
    
    if progress_data is None or model_data is None:
        print("\nâŒ ë¶„ì„í•  ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print("1. ë¨¼ì € ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("   python run_kiss.py -c data/input/exp3_cell_on_off/exp3_training_fixed.json")
        print("\n2. ê²°ê³¼ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ë¥¼ ì§€ì •í•˜ì„¸ìš”:")
        print("   python test_exp3_fixes.py --results_dir _/data/output")
        print("\n3. ìˆ˜ë™ìœ¼ë¡œ íŒŒì¼ ìœ„ì¹˜ í™•ì¸:")
        print("   find . -name '*exp3*' -name '*.json' 2>/dev/null")
        sys.exit(1)
    
    # ë¶„ì„ ìˆ˜í–‰
    analyze_power_measurements(progress_data)
    analyze_reward_distribution(progress_data)
    analyze_learning_convergence(model_data)
    analyze_efficiency_improvements(progress_data, model_data)
    analyze_regret_from_data(progress_data, model_data)

    # í”Œë¡¯ ìƒì„±
    if args.save_plots:
        save_dir = Path(args.results_dir)
        generate_diagnostic_plots(progress_data, save_dir)
    else:
        generate_diagnostic_plots(progress_data)
    
    print("\n" + "=" * 60)
    print("âœ… ê²€ì¦ ì™„ë£Œ!")
    
    # ì¢…í•© í‰ê°€
    baseline_power = progress_data.get('baseline_power', 0)
    reward_history = progress_data.get('reward_history', [])
    weights = np.array(model_data.get('weights', []))
    
    issues = []
    
    # ì „ë ¥ ë²”ìœ„ ìˆ˜ì •
    if baseline_power < 38 or baseline_power > 76:
        issues.append("ì „ë ¥ ì¸¡ì • ì´ìƒ")
    
    if len(reward_history) > 0:
        saturation_rate = np.sum(np.array(reward_history) >= 0.99) / len(reward_history)
        if saturation_rate > 0.8:
            issues.append("ë³´ìƒ í¬í™”")
    
    if len(weights) > 0:
        weight_ratio = weights.max() / max(weights.min(), 1e-10)
        if weight_ratio < 1.05:  # ê¸°ì¤€ ì™„í™”
            issues.append("í•™ìŠµ ìˆ˜ë ´ ë¶€ì¡± (ë” ê¸´ í•™ìŠµ í•„ìš”)")
    
    if issues:
        print(f"\nâš ï¸ ë°œê²¬ëœ ë¬¸ì œì : {', '.join(issues)}")
        print("ì¶”ê°€ íŠœë‹ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        print("\nğŸ‰ ëª¨ë“  ì§€í‘œê°€ ì •ìƒ ë²”ìœ„ ë‚´ì…ë‹ˆë‹¤!")

if __name__ == "__main__":
    main()